{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Getting Authors and Titles from Tabula-exported TSV Data\n",
    "\n",
    "The object: go from a list of tsv filenames (maybe I'll bin them by year?) to an array of [date, rank, weeks on list, title, author(s)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_filen = \"tabula-1963-03-17.tsv\"\n",
    "nf_filen = \"tabula-1963-03-17-nf.tsv\"\n",
    "#How far into the tsv file the data shows up...\n",
    "data_i = 2\n",
    "fields = ['rank','title+author','rank_last_week','weeks_on_list']\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def empty(row):\n",
    "    for r in row:\n",
    "        if r!=\"\":\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "def extract_date(datestr):\n",
    "    print datestr\n",
    "    date = datetime.strptime(datestr[0],'%B %d, %Y')\n",
    "    print date\n",
    "    return date\n",
    "\n",
    "##Indexes into row data_i of a tsv and then reads it into an array of arrays\n",
    "def read_tsv(name):\n",
    "    i = 0\n",
    "    arr = []\n",
    "    date = \"\"\n",
    "    with open(name) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if i ==0 :\n",
    "                date = extract_date([row[1]])\n",
    "            if ((i > data_i) & (not empty(row))):\n",
    "                arr.append([date]+row)\n",
    "            i = i+1\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['March 17, 1963']\n",
      "1963-03-17 00:00:00\n",
      "[[datetime.datetime(1963, 3, 17, 0, 0), '1', 'RAISE HIGH THE ROOF BEAM, CARPENTERS, by J.D. Salinger', '1', '5'], [datetime.datetime(1963, 3, 17, 0, 0), '2', 'SEVEN DAYS IN MAY, by Fletcher Knebel and Charles W. Bailey II.', '2', '25'], [datetime.datetime(1963, 3, 17, 0, 0), '3', 'THE SAND PEBBLES, by Richard McKenna.', '3', '9'], [datetime.datetime(1963, 3, 17, 0, 0), '4', 'FAIL-SAFE, by Eugene Burdick and Harvey Wheeler.', '4', '19'], [datetime.datetime(1963, 3, 17, 0, 0), '5', 'THE MOONSPINNERS, by Mary Stewart.', '5', '10'], [datetime.datetime(1963, 3, 17, 0, 0), '6', 'TRIUMPH, by Philip Wylie.', '9', '2'], [datetime.datetime(1963, 3, 17, 0, 0), '7', 'A SHADE OF DIFFERENCE, by Allen Drury.', '7', '23'], [datetime.datetime(1963, 3, 17, 0, 0), '8', '$100 MISUNDERSTANDING, by Robert Gover.', '--', '14'], [datetime.datetime(1963, 3, 17, 0, 0), '9', 'THE MOONFLOWER VINE, by Jetta Carleton', '6', '4'], [datetime.datetime(1963, 3, 17, 0, 0), '10', 'THE CENTAUR, by John Updike', '10', '2']]\n"
     ]
    }
   ],
   "source": [
    "commasv = read_tsv(f_filen)\n",
    "print commasv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('THE SAND PEBBLES', set(['Richard McKenna']))\n"
     ]
    }
   ],
   "source": [
    "sample_title_auth = commasv[2][2]\n",
    "#print sample_title_auth\n",
    "\n",
    "#index into phrase to skip \" by\"\n",
    "auth_i = 4\n",
    "\n",
    "def title_author_pair(data_str):\n",
    "    split_str = data_str.split(',')\n",
    "    title = \"\"\n",
    "    authors = set()\n",
    "    i=0\n",
    "    for phrase in split_str:\n",
    "        if i == 0:\n",
    "            title = phrase\n",
    "        else:\n",
    "            if phrase.isupper():\n",
    "                title = title + \", \"+phrase\n",
    "            else:\n",
    "                author_ph = phrase[auth_i:]\n",
    "                if \" and \" in author_ph:\n",
    "                    author_arr = author_ph.split(\" and \")\n",
    "                    for author in author_arr:\n",
    "                        if author[len(author)-1]=='.':\n",
    "                            author = author[:len(author)-1] # strip trailing period\n",
    "                        authors.add(author)\n",
    "                else:\n",
    "                    author = author_ph\n",
    "                    if author[len(author)-1]=='.':\n",
    "                        author = author[:len(author)-1] # strip trailing period\n",
    "                    authors.add(author)\n",
    "        i = i+1\n",
    "    return (title,authors)\n",
    "        \n",
    "print title_author_pair(sample_title_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RAISE HIGH THE ROOF BEAM,  CARPENTERS', set(['J.D. Salinger']))\n",
      "('SEVEN DAYS IN MAY', set(['Fletcher Knebel', 'Charles W. Bailey II']))\n",
      "('THE SAND PEBBLES', set(['Richard McKenna']))\n",
      "('FAIL-SAFE', set(['Eugene Burdick', 'Harvey Wheeler']))\n",
      "('THE MOONSPINNERS', set(['Mary Stewart']))\n",
      "('TRIUMPH', set(['Philip Wylie']))\n",
      "('A SHADE OF DIFFERENCE', set(['Allen Drury']))\n",
      "('$100 MISUNDERSTANDING', set(['Robert Gover']))\n",
      "('THE MOONFLOWER VINE', set(['Jetta Carleton']))\n",
      "('THE CENTAUR', set(['John Updike']))\n"
     ]
    }
   ],
   "source": [
    "for row in commasv:\n",
    "    print(title_author_pair(row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ISBN from Title/Author Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api-2445581351187.apicast.io:443/search?app_key=62f7cedf62afa7006026634aaadce211&app_id=7f7512d5&t=Potatoes\n",
      "http://isbndb.com/api/books.xml?access_key=1DR9S9TA&index1=title&value1=Potatoes\n",
      "('RAISE HIGH THE ROOF BEAM,  CARPENTERS', set(['J.D. Salinger']))\n",
      "<addinfourl at 139747567525616 whose fp = <socket._fileobject object at 0x7f1984aa9d50>>\n",
      "('0241950465', 'Raise High the Roof Beam, Carpenters', None)\n",
      "('0553142828', 'Raise high the roof beam, carpenters', None)\n",
      "('0140237518', 'Raise High the Roof Beam, Carpenters', 'J. D. Salinger, ')\n",
      "('0141049243', 'Raise High the Roof Beam, Carpenters. Seymour', 'J.D. Salinger, ')\n",
      "('055320596X', 'Raise high the roof beam, carpenters; and, Seymour', 'J. D. Salinger')\n",
      "('0316769517', 'Raise High the Roof Beam, Carpenters and Seymour', 'J. D. Salinger, ')\n",
      "('0140022643', 'Raise high the roof beam, carpenters; and Seymour', 'J. D. Salinger')\n",
      "('0316766941', 'Raise high the roof beam, carpenters', None)\n",
      "('0316769576', 'Raise high the roof beam, carpenters', None)\n",
      "('0553125540', 'Raise high the roof beam, carpenters', 'J. D. Salinger')\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "set(['0553125540', '0316769517', '055320596X', '0141049243', '0140237518', '0140022643'])\n",
      "('SEVEN DAYS IN MAY', set(['Fletcher Knebel', 'Charles W. Bailey II']))\n",
      "<addinfourl at 139747567847904 whose fp = <socket._fileobject object at 0x7f1984aa9e50>>\n",
      "('0553269569', 'SEVEN DAYS IN MAY', 'FLETCHER KNEBEL')\n",
      "('0854565558', 'Seven Days in May', 'Fletcher Knebel, ')\n",
      "('0553131699', 'Seven Days in May', 'Fletcher Knebel, ')\n",
      "('0060124369', 'Seven Days in May', 'F. Knebel, ')\n",
      "('1580812430', 'Seven Days In May', 'Kristin Sergel, ')\n",
      "('0060124350', 'Seven Days In May: A Novel', 'Fletcher Knebel, Charles W Bailey II, ')\n",
      "('0972908609', 'Seven Days in Missouri', None)\n",
      "('0609609793', 'Seven days & seven sins', 'Pamela Ditchoff')\n",
      "('1780882475', 'Stop bedwetting in seven days', 'Alicia Eaton.')\n",
      "('9780953917', 'Seven days in July', 'A.M. Coombs.')\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "set(['0553131699', '0854565558', '0060124350', '0553269569', '0060124369'])\n",
      "('THE SAND PEBBLES', set(['Richard McKenna']))\n",
      "<addinfourl at 139747566147920 whose fp = <socket._fileobject object at 0x7f1984aa9dd0>>\n",
      "('0948699310', 'Pebbles on the sand', 'Betty Blunt.')\n",
      "('0795305125', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0231109261', 'Realms of memory', 'under the direction of Pierre Nora; English language edition edited and with a foreword by Lawrence D. Kritzman; translated by Arthur Goldhammer')\n",
      "('1599534096', \"Pebbles, Sand, & Silt: The Neighbor's Garden\", 'Emily Sohn and Diane Bair, ')\n",
      "('0887060609', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0887060595', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0899668577', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0870215922', 'The sand pebbles', 'by Richard McKenna; with an introduction by Robert Shenk')\n",
      "('158909817X', 'Pebbles', 'Davis K. Thanjan, ')\n",
      "('0585061408', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "set(['0870215922', '0899668577', '0795305125'])\n",
      "('FAIL-SAFE', set(['Eugene Burdick', 'Harvey Wheeler']))\n",
      "<addinfourl at 139747567498376 whose fp = <socket._fileobject object at 0x7f1984aa9dd0>>\n",
      "('0749223707', 'Fail Safe', 'A. Demaid, ')\n",
      "('088001654X', 'Fail-safe', 'Eugene Burdick & Harvey Wheeler')\n",
      "('0971573212', 'Fail - Safe Leadership', 'Linda Martin, Dr. David G. Mutchler, ')\n",
      "('0399126163', 'Fail-safe investing', 'Peter Nagan')\n",
      "('0132995867', 'Fail-safe business negotiating', 'Philip Sperber')\n",
      "('0132995786', 'Fail-safe business negotiating', 'Philip Sperber')\n",
      "('0312247036', 'Fail-safe investing', 'Harry Browne')\n",
      "('046502274X', 'The fail-safe society', 'Charles Piller')\n",
      "('0471014389', 'Fail-safe small businesses', 'Ron Tepper')\n",
      "('0471014370', 'Fail-safe small businesses', 'Ron Tepper')\n",
      "Adding ISBN!\n",
      "set(['088001654X'])\n",
      "('THE MOONSPINNERS', set(['Mary Stewart']))\n",
      "<addinfourl at 139747567499240 whose fp = <socket._fileobject object at 0x7f19841ad550>>\n",
      "('0194216640', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0722331487', 'Moonspinner the grey', 'Mary Tuckett.')\n",
      "('3464127788', 'The Moonspinners.', 'Mary Stewart, Diane. Mowat, Bob Harvey, ')\n",
      "('0194230392', 'The Oxford Bookworms Library: Stage 4: 1,400 Headwords: The Moonspinners: 1400 Headwords', 'Mary Stewart, Diane Mowat, Tricia Hedge (Contributor), Jennifer Basset (Contributor)')\n",
      "('0905712412', 'The moonspinners; Nine coaches waiting; The ivy tree; Madam, will you talk?', 'Mary Stewart')\n",
      "('067717604X', 'The Moon-Spinners: A Spellbinding Suspense Thriller', 'Mary Stewart, Crest Books (Editor), A.E. Gunther (Editor), M.S. Mill (Editor), Walt Disney (Illustrator)')\n",
      "('0340013613', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0194791785', 'The Moonspinners', None)\n",
      "('0706610520', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0060502959', 'The Moonspinners', 'Mary Stewart, ')\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "set(['0340013613', '3464127788', '0905712412', '0194216640', '0060502959', '0706610520', '0194230392'])\n",
      "('TRIUMPH', set(['Philip Wylie']))\n",
      "<addinfourl at 139747566304432 whose fp = <socket._fileobject object at 0x7f1984aa9dd0>>\n",
      "('1740211901', \"Dolphin's Triumph\", None)\n",
      "('0670918717', 'Triumph', None)\n",
      "('1841497622', \"Orphan's Triumph\", None)\n",
      "('042507644X', 'Triumph', 'Oliver Payne, ')\n",
      "('1855321246', 'Triumph', 'Don Morley, ')\n",
      "('1594270260', 'Conditional triumphs', 'Bernard Saper.')\n",
      "('0263143007', 'Tangled triumphs', None)\n",
      "('0373085095', 'Tangled triumphs', 'Terri Herrington.')\n",
      "('0340411988', 'The triumph', 'Ernest K. Gann')\n",
      "('0851462324', 'Triumph acclaim', 'Autobooks.')\n",
      "set([])\n",
      "('A SHADE OF DIFFERENCE', set(['Allen Drury']))\n",
      "<addinfourl at 139747566640736 whose fp = <socket._fileobject object at 0x7f19841ad550>>\n",
      "('1562080016', 'A Shade of Difference', 'Allen Drury, ')\n",
      "('0385023898', 'Shade of Difference', 'ALLEN DRURY')\n",
      "('0520233174', 'A different shade of colonialism', 'Eve M. Troutt Powell')\n",
      "('0520233166', 'A different shade of colonialism', 'Eve M. Troutt Powell')\n",
      "('156584615X', 'A different shade of gray', 'Katherine S. Newman')\n",
      "('1575531143', 'Poems of different shades', 'Thomas M Kruger, ')\n",
      "('0889500851', 'Shades of difference', 'an essay by Dr. Ruth B. Phillips')\n",
      "('0585330468', 'ThinkPad: a different shade of blue', 'Deborah A. Dell, J. Gerry Purdy')\n",
      "('1846851696', 'A shade of light', 'E. George Thomas.')\n",
      "('1902309367', 'The substance of a shade', 'John Glasby.')\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "set(['0385023898', '1562080016'])\n",
      "('$100 MISUNDERSTANDING', set(['Robert Gover']))\n",
      "<addinfourl at 139747566638432 whose fp = <socket._fileobject object at 0x7f1984aa9e50>>\n",
      "('8484703266', 'Desavenencia/ Misunderstanding', 'Claude Boujon, ')\n",
      "('0802131816', 'One Hundred Dollar Misunderstanding', 'Robert Gover, ')\n",
      "('9578388209', '100', '... [et al.]')\n",
      "('9578388217', '100', '... [et al.]')\n",
      "('9578388225', '100', '... [et al.]')\n",
      "('0415063957', 'Mutual misunderstanding', None)\n",
      "('0714529680', 'Misunderstandings', 'Clive Collins')\n",
      "('9529029640', 'Fazer. 100', None)\n",
      "('3100685091', '100 Stunden', None)\n",
      "('9578388195', '100', '... [et al.]')\n",
      "set([])\n",
      "('THE MOONFLOWER VINE', set(['Jetta Carleton']))\n",
      "<addinfourl at 139747566640088 whose fp = <socket._fileobject object at 0x7f1984aa9d50>>\n",
      "('0061673234', 'The moonflower vine', 'Jetta Carleton; foreword by Jane Smiley')\n",
      "('156145138X', 'The Moonflower', 'Jean Loewer, Peter Loewer (Illustrator)')\n",
      "('0263105288', 'The moonflower', 'Valentine Luellen')\n",
      "('1567183859', 'Moonflower', 'Sirona Knight, ')\n",
      "('0491011113', 'The moonflower', None)\n",
      "('1561453145', 'The Moonflower', 'Peter Loewer, H. Peter Loewer, Jean Loewer (Illustrator)')\n",
      "('140523847X', 'The Mystical Moonflower', None)\n",
      "('0373821247', 'Night of the Moonflower', 'Anne Vinton, ')\n",
      "('0333131401', 'The frog in the moonflower', None)\n",
      "('0515033529', 'The Frog in the Moonflower', 'Ivor Drummond, ')\n",
      "Adding ISBN!\n",
      "set(['0061673234'])\n",
      "('THE CENTAUR', set(['John Updike']))\n",
      "<addinfourl at 139747567500032 whose fp = <socket._fileobject object at 0x7f1984aa9d50>>\n",
      "('023396360X', 'The centaur', None)\n",
      "('0233983058', 'The centaur', 'John Updike')\n",
      "('0394418816', 'The centaur', 'John Updike')\n",
      "('1557530769', 'The Centaur Types', 'Bruce Rogers, ')\n",
      "('1562791311', \"The centaur's son\", 'Philip Daughtry')\n",
      "('0955193249', 'The ant and the centaur', 'Stephen Brown.')\n",
      "('8472233820', 'El Centauro / The Centaur', 'John Updike, ')\n",
      "('0393038475', 'Dreams of the centaur', 'Montserrat Fontes')\n",
      "('0969280122', \"The Centaur's mountain\", 'Philip Resnick, Ron Walkey')\n",
      "('0916620069', 'The Mexican centaur', 'Oren Arnold')\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "set(['0394418816', '0233983058', '8472233820'])\n",
      "<addinfourl at 139747566768640 whose fp = <socket._fileobject object at 0x7f19841ad550>>\n",
      "('0948699310', 'Pebbles on the sand', 'Betty Blunt.')\n",
      "('0795305125', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0231109261', 'Realms of memory', 'under the direction of Pierre Nora; English language edition edited and with a foreword by Lawrence D. Kritzman; translated by Arthur Goldhammer')\n",
      "('1599534096', \"Pebbles, Sand, & Silt: The Neighbor's Garden\", 'Emily Sohn and Diane Bair, ')\n",
      "('0887060609', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0887060595', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0899668577', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0870215922', 'The sand pebbles', 'by Richard McKenna; with an introduction by Robert Shenk')\n",
      "('158909817X', 'Pebbles', 'Davis K. Thanjan, ')\n",
      "('0585061408', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n",
      "Adding ISBN!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0795305125', '0870215922', '0899668577'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree\n",
    "%run \"key.py\"\n",
    "\n",
    "suffixes = ['CPA', 'CSC', 'CSJ', 'DC', 'DD', 'DDS', 'DMD', 'DO', 'DVM', 'EDD', 'ESQ', 'II', 'III', \n",
    "            'IV', 'INC', 'JD', 'JR', 'LLD', 'LTD', 'MD', 'OD', 'OSB', 'PC', 'PE', 'PHD', 'RET', \n",
    "            'RGS', 'RN', 'RNC', 'SHCJ', 'SJ', 'SNJM', 'SR', 'SSMO', 'USA', 'USAF', 'USAFR', 'USAR', \n",
    "            'USCG', 'USMC', 'USMCR', 'USN', 'USNR']\n",
    "\n",
    "isbn_plus_base_url = \"https://api-2445581351187.apicast.io:443\"\n",
    "plus_key = isbn_plus_key\n",
    "app_id = \"7f7512d5\"\n",
    "search_plus = \"/search?app_key=\"+plus_key+\"&app_id=\"+app_id+\"&t=\"\n",
    "print isbn_plus_base_url+search_plus+\"Potatoes\"\n",
    "\n",
    "\n",
    "db_key = isbn_db_key\n",
    "isbn_db_base = \"http://isbndb.com/api\"\n",
    "search_db = \"/books.xml?access_key=\"+db_key+\"&index1=title&value1=\"\n",
    "print isbn_db_base+search_db+\"Potatoes\"\n",
    "\n",
    "def url_to_xml(url):\n",
    "    req = urllib2.Request(url)\n",
    "    req.add_header('User-agent', 'Mozilla 5.10')\n",
    "    res = urllib2.urlopen(req)\n",
    "    print res\n",
    "    data = xml.etree.ElementTree.parse(res).getroot()[0]\n",
    "    for book in data.findall('BookData'):\n",
    "        isbn = book.get('isbn')\n",
    "        title = book.find('Title').text\n",
    "        author = book.find('AuthorsText').text\n",
    "        print(isbn,title,author)\n",
    "    return data\n",
    "\n",
    "def suffix(phrase):\n",
    "    norm_phrase = phrase.replace(',',\"\").upper()\n",
    "    if norm_phrase in suffixes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def last_name_recursive(name,last_index):\n",
    "    if last_index == 0:\n",
    "        return \"\"\n",
    "    last_phrase = name[last_index]\n",
    "    if not suffix(last_phrase):\n",
    "        return last_phrase\n",
    "    else:\n",
    "        return last_name_recursive(name, last_index-1)\n",
    "\n",
    "def last_name(name):\n",
    "    names = name.split(\" \")\n",
    "    last_index = len(names)-1\n",
    "    last = last_name_recursive(names,last_index)\n",
    "    return last\n",
    "\n",
    "def norm_text(text):\n",
    "    return text.replace(\" \",\"\").replace(\".\",\"\").replace(\",\",\"\").lower()\n",
    "\n",
    "def is_book(booxml, title, authors, year):\n",
    "    xml_title = booxml.find('Title').text\n",
    "    norm_xml_title = norm_text(xml_title)\n",
    "    norm_title = norm_text(title)\n",
    "    if(norm_xml_title in norm_title) or (norm_title in norm_xml_title):\n",
    "        xml_authors = booxml.find('AuthorsText').text\n",
    "        if xml_authors is None:\n",
    "            return False\n",
    "        for author in authors:\n",
    "            if norm_text(author) in norm_text(xml_authors):\n",
    "                print \"Adding ISBN!\"\n",
    "                return True\n",
    "            if norm_text(last_name(author)) in norm_text(xml_authors):\n",
    "                print \"Adding ISBN!\"\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def get_isbns(title,authors,year):\n",
    "    isbns = set()\n",
    "    search_t = convert_to_search(title)\n",
    "    url = isbn_db_base+search_db+search_t\n",
    "#    print row[0].year\n",
    "    data = url_to_xml(url)\n",
    "    for book in data:\n",
    "        if (is_book(book,title,authors,year)):\n",
    "            isbns.add(book.get('isbn'))\n",
    "    return isbns\n",
    "\n",
    "for row in commasv:\n",
    "    title_author = title_author_pair(row[2])\n",
    "    print title_author\n",
    "    isbns = get_isbns(title_author[0],title_author[1],1963)\n",
    "    print isbns\n",
    "    \n",
    "get_isbns(\"The Sand Pebbles\", set(['Richard McKenna']), 1963)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Wiki Gender Data from Author Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_name_to_id = \"https://www.wikidata.org/w/api.php?action=wbsearchentities&language=en&format=json&search=\"\n",
    "wiki_id_to_gender = \"https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=\"\n",
    "gender_prop_id = \"P21\"\n",
    "wiki_gender_hash = {\"Q6581097\":\"male\", \"Q6581072\":\"female\",\"Q1052281\":\"transf\",\"Q2449503\":\"transm\",\"Q1097630\":\"intersex\"}\n",
    "\n",
    "import urllib2\n",
    "import json\n",
    "\n",
    "def url_to_data( url ):\n",
    "    req = urllib2.Request(url)\n",
    "    req.add_header('User-agent', 'Mozilla 5.10')\n",
    "    res = urllib2.urlopen(req)\n",
    "    data = json.load(res)\n",
    "    return data\n",
    "\n",
    "def convert_to_search(name):\n",
    "    return_string = \"\"\n",
    "    last_ch = \" \"\n",
    "    for ch in name:\n",
    "        if (ch == \" \"):\n",
    "            if (last_ch != \".\"):\n",
    "                return_string = return_string + \"+\"\n",
    "        else:\n",
    "            if ch == \".\":\n",
    "                return_string = return_string +\".+\"\n",
    "            else:\n",
    "                return_string = return_string+ch\n",
    "        last_ch = ch\n",
    "    return return_string\n",
    "\n",
    "## This needs to disambiguate -- does it need to pull more information by id?\n",
    "def disambiguate(entity_data, name):\n",
    "    entities = []\n",
    "    for entity in entity_data:\n",
    "        if 'description' in entity:\n",
    "            desc = entity['description']\n",
    "            ent_id = entity['id']\n",
    "            if ('novel' in desc) or ('write' in desc) or ('auth' in desc) or ('cartoo' in desc) or ('comic' in desc):\n",
    "                entities.append((ent_id,desc))\n",
    "    if len(entities)==1:\n",
    "        return entities[0][0]\n",
    "    else:\n",
    "        for x in entities:\n",
    "            print x\n",
    "        print \"User input needed for \"+name\n",
    "        return -1\n",
    "\n",
    "def get_wiki_id(name):\n",
    "    search_term = convert_to_search(name)\n",
    "    url = wiki_name_to_id + search_term\n",
    "    data = url_to_data(url)['search']\n",
    "    if data == []:\n",
    "        return -1\n",
    "    i = disambiguate(data,name)\n",
    "    return i\n",
    "\n",
    "def gender_from_id(auth_id):\n",
    "    url = wiki_id_to_gender + auth_id\n",
    "    print url\n",
    "    claims = url_to_data(url)['entities'][str(auth_id)]['claims']['P21']\n",
    "    gender_arr =[]\n",
    "    for claim in claims:\n",
    "        if claim['mainsnak']['datavalue']['value'] is not None:\n",
    "            gender_id = claim['mainsnak']['datavalue']['value']['id']\n",
    "            gender_arr.append(wiki_gender_hash[gender_id])\n",
    "    if len(gender_arr)>1:\n",
    "        gender = max_value(gender_arr)\n",
    "    else:\n",
    "        gender = gender_arr[0]\n",
    "    return gender\n",
    "\n",
    "\n",
    "#def book_to_key_facts(book_data):\n",
    "    \n",
    "    \n",
    "\n",
    "def author_to_gender(author_name):\n",
    "    gender = \"\"\n",
    "    author_id = get_wiki_id(author_name)\n",
    "    if author_id == -1:\n",
    "        print \"Unable to find \"+author_name+\" in database\"\n",
    "        return \"unknown\"\n",
    "    gender = gender_from_id(author_id)\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q298920\n"
     ]
    }
   ],
   "source": [
    "print get_wiki_id(\"Charles M. Schulz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q39212\n",
      "John Steinbeck was a male\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q298920\n",
      "Charles M. Schulz was a male\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q353774\n",
      "Adela Rogers St. Johns was a female\n",
      "User input needed for Hedda Hopper\n",
      "Unable to find Hedda Hopper in database\n",
      "Hedda Hopper was a unknown\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q15637611\n",
      "Virginia Cary Hudson was a female\n",
      "(u'Q273210', u'(1924-1987) writer from the United States')\n",
      "(u'Q15976232', u'(1841-1925) American editor and author')\n",
      "(u'Q18529778', u'British judge and writer')\n",
      "User input needed for James Baldwin\n",
      "Unable to find James Baldwin in database\n",
      "James Baldwin was a unknown\n",
      "User input needed for Rachel Carson\n",
      "Unable to find Rachel Carson in database\n",
      "Rachel Carson was a unknown\n",
      "User input needed for Louis Nizer\n",
      "Unable to find Louis Nizer in database\n",
      "Louis Nizer was a unknown\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q361617\n",
      "E.B. White was a male\n",
      "Unable to find Edmond Taylor in database\n",
      "Edmond Taylor was a unknown\n"
     ]
    }
   ],
   "source": [
    "for row in commasv:\n",
    "    authors = title_author_pair(row[2])[1]\n",
    "    for author in authors:\n",
    "        gender = author_to_gender(author)\n",
    "        print author + \" was a \"+gender"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
