{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Getting Authors and Titles from Tabula-exported TSV Data\n",
    "\n",
    "The object: go from a list of tsv filenames (maybe I'll bin them by year?) to an array of [date, rank, weeks on list, title, author(s)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['March 17, 1963']\n",
      "1963-03-17 00:00:00\n",
      "[[datetime.datetime(1963, 3, 17, 0, 0), '1', 'TRAVELS WITH CHARLEY, by John Steinbeck.', '1', '32'], [datetime.datetime(1963, 3, 17, 0, 0), '2', 'HAPPINESS IS A WARM PUPPY, by Charles M. Schulz.', '2', '13'], [datetime.datetime(1963, 3, 17, 0, 0), '3', 'FINAL VERDICT, by Adela Rogers St. Johns.', '4', '27'], [datetime.datetime(1963, 3, 17, 0, 0), '4', 'THE WHOLE TRUTH AND NOTHING BUT, by Hedda Hopper.', '7', '2'], [datetime.datetime(1963, 3, 17, 0, 0), '5', 'O YE JIGS & JULEPS!, by Virginia Cary Hudson.', '3', '43'], [datetime.datetime(1963, 3, 17, 0, 0), '6', 'THE FIRE NEXT TIME, by James Baldwin', '6', '3'], [datetime.datetime(1963, 3, 17, 0, 0), '7', 'SILENT SPRING, by Rachel Carson.', '5', '24'], [datetime.datetime(1963, 3, 17, 0, 0), '8', 'MY LIFE IN COURT, by Louis Nizer.', '10', '68'], [datetime.datetime(1963, 3, 17, 0, 0), '9', 'POINTS OF MY COMPASS, by E.B. White.', '8', '5'], [datetime.datetime(1963, 3, 17, 0, 0), '10', 'THE FALL OF THE DYNASTIES, by Edmond Taylor.', '9', '2']]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree\n",
    "import urllib2\n",
    "import re, string\n",
    "\n",
    "f_filen = \"tabula-1963-03-17.tsv\"\n",
    "nf_filen = \"tabula-1963-03-17-nf.tsv\"\n",
    "#How far into the tsv file the data shows up...\n",
    "data_i = 2\n",
    "fields = ['rank','title+author','rank_last_week','weeks_on_list']\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def empty(row):\n",
    "    for r in row:\n",
    "        if r!=\"\":\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "def extract_date(datestr):\n",
    "    print datestr\n",
    "    date = datetime.strptime(datestr[0],'%B %d, %Y')\n",
    "    print date\n",
    "    return date\n",
    "\n",
    "##Indexes into row data_i of a tsv and then reads it into an array of arrays\n",
    "def read_tsv(name):\n",
    "    i = 0\n",
    "    arr = []\n",
    "    date = \"\"\n",
    "    with open(name) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if i ==0 :\n",
    "                date = extract_date([row[1]])\n",
    "            if ((i > data_i) & (not empty(row))):\n",
    "                arr.append([date]+row)\n",
    "            i = i+1\n",
    "        return arr\n",
    "    \n",
    "commasv = read_tsv(nf_filen)\n",
    "print commasv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['March 17, 1963']\n",
      "1963-03-17 00:00:00\n",
      "['May 12, 1963']\n",
      "1963-05-12 00:00:00\n",
      "['March 31, 1963']\n",
      "1963-03-31 00:00:00\n",
      "['May 5, 1963']\n",
      "1963-05-05 00:00:00\n",
      "['May 26, 1963']\n",
      "1963-05-26 00:00:00\n",
      "['March 24, 1963']\n",
      "1963-03-24 00:00:00\n",
      "['April 7, 1963']\n",
      "1963-04-07 00:00:00\n",
      "['April 14, 1963']\n",
      "1963-04-14 00:00:00\n",
      "['April 28, 1963']\n",
      "1963-04-28 00:00:00\n",
      "['May 19, 1963']\n",
      "1963-05-19 00:00:00\n",
      "['April 21, 1963']\n",
      "1963-04-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def read_folder(folderpath):\n",
    "    empty_array = []\n",
    "    for f in os.listdir(folderpath):\n",
    "        commasv = read_tsv(path+f)\n",
    "        empty_array.append(commasv)\n",
    "    return empty_array\n",
    "\n",
    "path = \"1963/fiction/\"\n",
    "sixtythree = read_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manual_titles = []\n",
    "manual_genders = []\n",
    "done_dict = {}\n",
    "viaf_dict={}\n",
    "gender_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<addinfourl at 139826564734776 whose fp = <socket._fileobject object at 0x7f2bd0dcbdd0>>\n",
      "('0241950465', 'Raise High the Roof Beam, Carpenters', None)\n",
      "('0553142828', 'Raise high the roof beam, carpenters', None)\n",
      "('0140237518', 'Raise High the Roof Beam, Carpenters', 'J. D. Salinger, ')\n",
      "('0141049243', 'Raise High the Roof Beam, Carpenters. Seymour', 'J.D. Salinger, ')\n",
      "('055320596X', 'Raise high the roof beam, carpenters; and, Seymour', 'J. D. Salinger')\n",
      "('0316769517', 'Raise High the Roof Beam, Carpenters and Seymour', 'J. D. Salinger, ')\n",
      "('0140022643', 'Raise high the roof beam, carpenters; and Seymour', 'J. D. Salinger')\n",
      "('0316766941', 'Raise high the roof beam, carpenters', None)\n",
      "('0316769576', 'Raise high the roof beam, carpenters', None)\n",
      "('0553125540', 'Raise high the roof beam, carpenters', 'J. D. Salinger')\n",
      "Adding ISBN! Raise High the Roof Beam, Carpenters by J. D. Salinger, \n",
      "Adding ISBN! Raise High the Roof Beam, Carpenters. Seymour by J.D. Salinger, \n",
      "Adding ISBN! Raise high the roof beam, carpenters; and, Seymour by J. D. Salinger\n",
      "Adding ISBN! Raise High the Roof Beam, Carpenters and Seymour by J. D. Salinger, \n",
      "Adding ISBN! Raise high the roof beam, carpenters; and Seymour by J. D. Salinger\n",
      "Adding ISBN! Raise high the roof beam, carpenters by J. D. Salinger\n",
      "<addinfourl at 139826078814504 whose fp = <socket._fileobject object at 0x7f2bd0dcbdd0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.5', '813.54', '813', 'FIC', '833 / 823.91', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826078703560 whose fp = <socket._fileobject object at 0x7f2bd0dcbdd0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.5', '813.54', '813', 'FIC', '833 / 823.91', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826078447736 whose fp = <socket._fileobject object at 0x7f2bd0dcbf50>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.5', '813.54', '813', 'FIC', '833 / 823.91', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826169499304 whose fp = <socket._fileobject object at 0x7f2bd0dcbb50>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.5', '813.54', '813', 'FIC', '833 / 823.91', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826078594400 whose fp = <socket._fileobject object at 0x7f2bcbbce350>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.5', '813.54', '813', 'FIC', '833 / 823.91', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826078445864 whose fp = <socket._fileobject object at 0x7f2bcbbce350>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.5', '813.54', '813', 'FIC', '833 / 823.91', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826078220728 whose fp = <socket._fileobject object at 0x7f2bcbbce7d0>>\n",
      "('0553269569', 'SEVEN DAYS IN MAY', 'FLETCHER KNEBEL')\n",
      "('0854565558', 'Seven Days in May', 'Fletcher Knebel, ')\n",
      "('0553131699', 'Seven Days in May', 'Fletcher Knebel, ')\n",
      "('0060124369', 'Seven Days in May', 'F. Knebel, ')\n",
      "('1580812430', 'Seven Days In May', 'Kristin Sergel, ')\n",
      "('0060124350', 'Seven Days In May: A Novel', 'Fletcher Knebel, Charles W Bailey II, ')\n",
      "('0972908609', 'Seven Days in Missouri', None)\n",
      "('0609609793', 'Seven days & seven sins', 'Pamela Ditchoff')\n",
      "('1780882475', 'Stop bedwetting in seven days', 'Alicia Eaton.')\n",
      "('9780953917', 'Seven days in July', 'A.M. Coombs.')\n",
      "Adding ISBN! SEVEN DAYS IN MAY by FLETCHER KNEBEL\n",
      "Adding ISBN! Seven Days in May by Fletcher Knebel, \n",
      "Adding ISBN! Seven Days in May by Fletcher Knebel, \n",
      "Adding ISBN! Seven Days In May: A Novel by Fletcher Knebel, Charles W Bailey II, \n",
      "<addinfourl at 139826078258312 whose fp = <socket._fileobject object at 0x7f2bcbbce7d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813', '813.54', 'FIC', '823.91', '823.914', '813.4 / 823', 'Unclassified']\n",
      "<addinfourl at 139826078220440 whose fp = <socket._fileobject object at 0x7f2bcbbcead0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813', '813.54', 'FIC', '823.91', '823.914', '813.4 / 823', 'Unclassified']\n",
      "<addinfourl at 139826077922512 whose fp = <socket._fileobject object at 0x7f2bcbbcee50>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<addinfourl at 139826077923376 whose fp = <socket._fileobject object at 0x7f2bcbbceed0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813', '813.54', 'FIC', '823.91', '823.914', '813.4 / 823', 'Unclassified']\n",
      "<addinfourl at 139826078412456 whose fp = <socket._fileobject object at 0x7f2bcbbcee50>>\n",
      "('0140236740', \"The glass blower's breath\", 'Sunetra Gupta')\n",
      "('1568495617', 'The Glass Blowers', 'Daphne, Dame Du Maurier, ')\n",
      "('0862251486', 'The Glass-Blowers', 'Daphne Du Maurier, ')\n",
      "('0708981763', 'The Glass Blowers', 'Dame Daphne Du Maurier, ')\n",
      "('0575010800', 'The glass-blowers', 'by Daphne du Maurier')\n",
      "('0140024034', 'The glass-blowers', 'Daphne du Maurier')\n",
      "('0575029226', 'The glass-blowers', 'by Daphne du Maurier')\n",
      "('0590551825', 'Rosie & Jim and the glass blowers', 'written by John Cunliffe ; illustrated by Celia Berridge')\n",
      "('184408065X', 'The Glass-Blowers', 'Daphne Du Maurier, Michelle De Kretser (Introduction)')\n",
      "('081613491X', 'The glass-blowers', 'Daphne du Maurier')\n",
      "Adding ISBN! The Glass-Blowers by Daphne Du Maurier, \n",
      "Adding ISBN! The Glass Blowers by Dame Daphne Du Maurier, \n",
      "Adding ISBN! The glass-blowers by by Daphne du Maurier\n",
      "Adding ISBN! The glass-blowers by Daphne du Maurier\n",
      "Adding ISBN! The glass-blowers by by Daphne du Maurier\n",
      "Adding ISBN! The Glass-Blowers by Daphne Du Maurier, Michelle De Kretser (Introduction)\n",
      "Adding ISBN! The glass-blowers by Daphne du Maurier\n",
      "<addinfourl at 139826078223248 whose fp = <socket._fileobject object at 0x7f2bcbbcecd0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "<addinfourl at 139826078089440 whose fp = <socket._fileobject object at 0x7f2bcbb4f2d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "<addinfourl at 139826077691984 whose fp = <socket._fileobject object at 0x7f2bcbb4f650>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "<addinfourl at 139826078089944 whose fp = <socket._fileobject object at 0x7f2bcbb4f4d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "<addinfourl at 139826077811992 whose fp = <socket._fileobject object at 0x7f2bcbb4f9d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<addinfourl at 139826077813000 whose fp = <socket._fileobject object at 0x7f2bcbb4f4d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "<addinfourl at 139826077408648 whose fp = <socket._fileobject object at 0x7f2bcbb4fdd0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "<addinfourl at 139826077847136 whose fp = <socket._fileobject object at 0x7f2bcbb4fad0>>\n",
      "('0948699310', 'Pebbles on the sand', 'Betty Blunt.')\n",
      "('0795305125', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0231109261', 'Realms of memory', 'under the direction of Pierre Nora; English language edition edited and with a foreword by Lawrence D. Kritzman; translated by Arthur Goldhammer')\n",
      "('1599534096', \"Pebbles, Sand, & Silt: The Neighbor's Garden\", 'Emily Sohn and Diane Bair, ')\n",
      "('0887060609', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0887060595', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0899668577', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0870215922', 'The sand pebbles', 'by Richard McKenna; with an introduction by Robert Shenk')\n",
      "('158909817X', 'Pebbles', 'Davis K. Thanjan, ')\n",
      "('0585061408', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "Adding ISBN! The Sand Pebbles by Richard McKenna, \n",
      "Adding ISBN! The Sand Pebbles by Richard McKenna, \n",
      "Adding ISBN! The sand pebbles by by Richard McKenna; with an introduction by Robert Shenk\n",
      "<addinfourl at 139826077449320 whose fp = <socket._fileobject object at 0x7f2bcbb4fcd0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.54', '823.91', '791', 'FIC / 813.5', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826077528936 whose fp = <socket._fileobject object at 0x7f2bcbaec050>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.54', '823.91', '791', 'FIC / 813.5', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826077117472 whose fp = <socket._fileobject object at 0x7f2bcbaec3d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.54', '823.91', '791', 'FIC / 813.5', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826077530088 whose fp = <socket._fileobject object at 0x7f2bcbaec2d0>>\n",
      "('0194216640', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0722331487', 'Moonspinner the grey', 'Mary Tuckett.')\n",
      "('3464127788', 'The Moonspinners.', 'Mary Stewart, Diane. Mowat, Bob Harvey, ')\n",
      "('0194230392', 'The Oxford Bookworms Library: Stage 4: 1,400 Headwords: The Moonspinners: 1400 Headwords', 'Mary Stewart, Diane Mowat, Tricia Hedge (Contributor), Jennifer Basset (Contributor)')\n",
      "('0905712412', 'The moonspinners; Nine coaches waiting; The ivy tree; Madam, will you talk?', 'Mary Stewart')\n",
      "('067717604X', 'The Moon-Spinners: A Spellbinding Suspense Thriller', 'Mary Stewart, Crest Books (Editor), A.E. Gunther (Editor), M.S. Mill (Editor), Walt Disney (Illustrator)')\n",
      "('0340013613', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0194791785', 'The Moonspinners', None)\n",
      "('0706610520', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0060502959', 'The Moonspinners', 'Mary Stewart, ')\n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "Adding ISBN! The Moonspinners. by Mary Stewart, Diane. Mowat, Bob Harvey, \n",
      "Adding ISBN! The Oxford Bookworms Library: Stage 4: 1,400 Headwords: The Moonspinners: 1400 Headwords by Mary Stewart, Diane Mowat, Tricia Hedge (Contributor), Jennifer Basset (Contributor)\n",
      "Adding ISBN! The moonspinners; Nine coaches waiting; The ivy tree; Madam, will you talk? by Mary Stewart\n",
      "Adding ISBN! The Moon-Spinners: A Spellbinding Suspense Thriller by Mary Stewart, Crest Books (Editor), A.E. Gunther (Editor), M.S. Mill (Editor), Walt Disney (Illustrator)\n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "<addinfourl at 139826077162960 whose fp = <socket._fileobject object at 0x7f2bcbaec1d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.9', '823.914', 'FIC', '823.91', '428.6', '823', 'Unclassified']\n",
      "<addinfourl at 139826077160152 whose fp = <socket._fileobject object at 0x7f2bd0dcbf50>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<addinfourl at 139826077160656 whose fp = <socket._fileobject object at 0x7f2bd0dcb5d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.914', 'Unclassified']\n",
      "<addinfourl at 139826077114736 whose fp = <socket._fileobject object at 0x7f2bcbaec1d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<addinfourl at 139826077115528 whose fp = <socket._fileobject object at 0x7f2bcbaec050>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<addinfourl at 139826077530880 whose fp = <socket._fileobject object at 0x7f2bcbaec4d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.9', '823.914', 'FIC', '823.91', '428.6', '823', 'Unclassified']\n",
      "<addinfourl at 139826077115024 whose fp = <socket._fileobject object at 0x7f2bd0dcb1d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.9', '823.914', 'FIC', '823.91', '428.6', '823', 'Unclassified']\n",
      "<addinfourl at 139826077921360 whose fp = <socket._fileobject object at 0x7f2bcbaec750>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.9', '823.914', 'FIC', '823.91', '428.6', '823', 'Unclassified']\n",
      "{'oclc_id': '648365', 'holdings': '3031', 'subjects': [{'fast_id': '1207225', 'subject': 'Greece--Crete'}, {'fast_id': '1165132', 'subject': 'Vendetta'}, {'fast_id': '910817', 'subject': 'English fiction'}, {'fast_id': '839044', 'subject': 'British'}, {'fast_id': '911670', 'subject': 'English language--Study and teaching'}, {'fast_id': '1090601', 'subject': 'Readers (Elementary)'}], 'genders': [u'Female'], 'isbn': '0706610520', 'categories': [{'percent': '36.57652', 'label': '823.9'}, {'percent': '33.5752', 'label': '823.914'}, {'percent': '7.4208446', 'label': 'FIC'}, {'percent': '5.9366755', 'label': '823.91'}, {'percent': '4.551451', 'label': '428.6'}, {'percent': '3.3311346', 'label': '823'}, {'percent': '9.861478', 'label': 'Unclassified'}]}\n",
      "{'oclc_id': '21056380', 'holdings': '246', 'subjects': [{'fast_id': '1002985', 'subject': 'Romance fiction'}, {'fast_id': '1029781', 'subject': 'Murder'}], 'genders': [u'Female'], 'isbn': '0905712412', 'categories': [{'percent': '95.93496', 'label': '823.914'}, {'percent': '4.0650406', 'label': 'Unclassified'}]}\n",
      "<addinfourl at 139826077814224 whose fp = <socket._fileobject object at 0x7f2bcbaec050>>\n",
      "('0449213870', 'Grandmother and the Priests', 'Taylor Caldwell, ')\n",
      "('0449240274', 'Grandmother and the priests', 'Taylor Caldwell')\n",
      "('0665056354', 'His grandmothers', None)\n",
      "('0749397314', \"The Grandmother's Tale\", 'R K Narayan, ')\n",
      "('051707009X', \"The Grandmother's Book\", 'Marcia O. Levin, ')\n",
      "('1550373374', 'The Grandmother Doll', None)\n",
      "('0823304442', \"Grandmother's quilt\", 'Esther Buffler')\n",
      "('0882291289', 'The single grandmother', None)\n",
      "('0879052538', \"The grandmothers' club\", 'Alan Cheuse')\n",
      "('0416660606', 'The grandmother stone', 'Margaret Greaves')\n",
      "Adding ISBN! Grandmother and the Priests by Taylor Caldwell, \n",
      "Adding ISBN! Grandmother and the priests by Taylor Caldwell\n",
      "<addinfourl at 139826078222384 whose fp = <socket._fileobject object at 0x7f2bcbaec050>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.52', '813', 'FIC / 813.5', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826078777496 whose fp = <socket._fileobject object at 0x7f2bcbaecad0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.52', '813', 'FIC / 813.5', 'Unclassified', 'Other']\n",
      "<addinfourl at 139826078486824 whose fp = <socket._fileobject object at 0x7f2bcbaecf50>>\n",
      "('0061673234', 'The moonflower vine', 'Jetta Carleton; foreword by Jane Smiley')\n",
      "('156145138X', 'The Moonflower', 'Jean Loewer, Peter Loewer (Illustrator)')\n",
      "('0263105288', 'The moonflower', 'Valentine Luellen')\n",
      "('1567183859', 'Moonflower', 'Sirona Knight, ')\n",
      "('0491011113', 'The moonflower', None)\n",
      "('1561453145', 'The Moonflower', 'Peter Loewer, H. Peter Loewer, Jean Loewer (Illustrator)')\n",
      "('140523847X', 'The Mystical Moonflower', None)\n",
      "('0373821247', 'Night of the Moonflower', 'Anne Vinton, ')\n",
      "('0333131401', 'The frog in the moonflower', None)\n",
      "('0515033529', 'The Frog in the Moonflower', 'Ivor Drummond, ')\n",
      "Adding ISBN! The moonflower vine by Jetta Carleton; foreword by Jane Smiley\n",
      "<addinfourl at 139826077438248 whose fp = <socket._fileobject object at 0x7f2bcbaeced0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['813.54', 'FIC', '823.91 / 813', '818.5', '823.914 / 810 / 839.31 / B / 813.5 / 823', 'Unclassified']\n",
      "<addinfourl at 139826078486824 whose fp = <socket._fileobject object at 0x7f2bcbaecd50>>\n",
      "('0749223707', 'Fail Safe', 'A. Demaid, ')\n",
      "('088001654X', 'Fail-safe', 'Eugene Burdick & Harvey Wheeler')\n",
      "('0971573212', 'Fail - Safe Leadership', 'Linda Martin, Dr. David G. Mutchler, ')\n",
      "('0399126163', 'Fail-safe investing', 'Peter Nagan')\n",
      "('0132995867', 'Fail-safe business negotiating', 'Philip Sperber')\n",
      "('0132995786', 'Fail-safe business negotiating', 'Philip Sperber')\n",
      "('0312247036', 'Fail-safe investing', 'Harry Browne')\n",
      "('046502274X', 'The fail-safe society', 'Charles Piller')\n",
      "('0471014389', 'Fail-safe small businesses', 'Ron Tepper')\n",
      "('0471014370', 'Fail-safe small businesses', 'Ron Tepper')\n",
      "Adding ISBN! Fail-safe by Eugene Burdick & Harvey Wheeler\n",
      "<addinfourl at 139826078449608 whose fp = <socket._fileobject object at 0x7f2bcbaecb50>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['FIC', '813.54', '823.91', '813', '813.5', '823.914', 'Unclassified']\n",
      "<addinfourl at 139826077257312 whose fp = <socket._fileobject object at 0x7f2bcbadd2d0>>\n",
      "('1740211901', \"Dolphin's Triumph\", None)\n",
      "('0670918717', 'Triumph', None)\n",
      "('1841497622', \"Orphan's Triumph\", None)\n",
      "('042507644X', 'Triumph', 'Oliver Payne, ')\n",
      "('1855321246', 'Triumph', 'Don Morley, ')\n",
      "('1594270260', 'Conditional triumphs', 'Bernard Saper.')\n",
      "('0263143007', 'Tangled triumphs', None)\n",
      "('0373085095', 'Tangled triumphs', 'Terri Herrington.')\n",
      "('0340411988', 'The triumph', 'Ernest K. Gann')\n",
      "('0851462324', 'Triumph acclaim', 'Autobooks.')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ade5ab9c0ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msixtythree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-ade5ab9c0ba6>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(ls)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moclc_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misbns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mgender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genders'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0msubjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'holdings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#print sixtythree[4]\n",
    "\n",
    "def batch_process_lists(list_of_lists):\n",
    "    batch_target = []\n",
    "    for ls in list_of_lists:\n",
    "        batch_target = batch_target + process(ls)\n",
    "    return batch_target    \n",
    "\n",
    "def process(ls):\n",
    "    target = []\n",
    "    for row in ls:\n",
    "        date = row[0]\n",
    "        ranks = {\"this_week\":row[1],\"last_week\":row[3],\"weeks_on_list\":row[4]}\n",
    "        ta_tuple = title_author_pair(row[2])\n",
    "        title = ta_tuple[0]\n",
    "        authors = ta_tuple[1]\n",
    "        isbns = get_isbns(title,authors)\n",
    "        data = oclc_process(isbns,authors)\n",
    "        if data is not None:\n",
    "            if len(data)>0:\n",
    "                gender = data[0]['genders']\n",
    "                categories = data[0]['categories']\n",
    "                subjects = data[0]['holdings']\n",
    "                new_row = [title,authors,date,date.year,ranks,isbns,gender,subjects]\n",
    "                target.append(new_row)\n",
    "    return target\n",
    "\n",
    "for x in process(sixtythree[8]):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<addinfourl at 139826181112680 whose fp = <socket._fileobject object at 0x7f2bd1909dd0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "{'ddc': [{'percent': '70.82758', 'label': '823.91'}, {'percent': '21.310345', 'label': '823.912'}, {'percent': '0.5862069', 'label': '820'}, {'percent': '0.1724138', 'label': 'FIC'}, {'percent': '0.03448276', 'label': '823.3'}, {'percent': '7.0689654', 'label': 'Unclassified'}], 'holdings': '2873', 'subjects': [{'fast_id': '1204289', 'subject': 'France'}, {'fast_id': '1354514', 'subject': 'Revolution (France : 1789-1799)'}, {'fast_id': '943191', 'subject': 'Glass manufacture'}, {'fast_id': '19563', 'subject': 'Louis XVII, of France, 1785-1795'}], 'oclc_id': '20377499', 'authors': [{'viaf': '24600806', 'name': 'Du Maurier, Daphne, 1907-1989'}]}\n",
      "2873\n"
     ]
    }
   ],
   "source": [
    "oclc_base = \"http://classify.oclc.org/classify2/Classify?\"\n",
    "gender_dict = {}\n",
    "\n",
    "# Returns an array of dicts format {'isbn':isbn,'oclc_id':oclc_i,'subjects'\n",
    "# :subjects,'categories':categories,'genders':genders} if array lenghth > 1\n",
    "# use sum_oclc to resolve/synthesize\n",
    "def oclc_process(isbn_ls,authors):\n",
    "    target = []\n",
    "    done = []\n",
    "    for isbn in isbn_ls:\n",
    "        oclc_data = get_oclc_data(isbn)\n",
    "        if (oclc_data['oclc_id'] not in done) and (oclc_data['holdings']!=0): \n",
    "            oclc_id = oclc_data['oclc_id']\n",
    "            holdings = oclc_data['holdings']\n",
    "            subjects = oclc_data['subjects']\n",
    "            categories = oclc_data['ddc']\n",
    "            genders = extract_gender(oclc_data['authors'],authors)\n",
    "            row = {'isbn':isbn,'oclc_id':oclc_id,'subjects':subjects,'categories':categories,'genders':genders, 'holdings':holdings}\n",
    "            done.append(oclc_id)\n",
    "            target.append(row)\n",
    "    if len(target)>1:\n",
    "        for row in target:\n",
    "            print row\n",
    "    return target\n",
    "         \n",
    "def max_holding(oarr):\n",
    "    target = {}\n",
    "    previous = oarr[0]\n",
    "    for o in oarr:\n",
    "        if o['holdings']>previous['holdings']:\n",
    "            target = o\n",
    "        previous = o\n",
    "    return target\n",
    "        \n",
    "def url_to_x(url):\n",
    "    req = urllib2.Request(url)\n",
    "    req.add_header('User-agent', 'Mozilla 5.10')\n",
    "    res = urllib2.urlopen(req)\n",
    "    print res\n",
    "    data = xml.etree.ElementTree.parse(res).getroot()\n",
    "    return data\n",
    "        \n",
    "def extract_gender(oclc_a,author_ls):\n",
    "    genders = []\n",
    "    for a in author_ls:\n",
    "        if a in gender_dict:\n",
    "            genders.append(gender_dict[a])\n",
    "        else:\n",
    "            viaf_id = get_viaf_id(oclc_a,a)\n",
    "            if viaf_id != \"\":\n",
    "                viaf_dict[a] = viaf_id\n",
    "                gender = get_gender_scrape(viaf_id)\n",
    "                if gender != \"\":\n",
    "                    gender_dict[a] = gender\n",
    "                genders.append(gender)\n",
    "    return genders\n",
    "            \n",
    "# Should I go into the VIAF and try to match the various labels?\n",
    "def get_viaf_id(oclc_a_list,author):\n",
    "    if author in viaf_dict:\n",
    "        return viaf_dict[author]\n",
    "    candidate = \"\"\n",
    "    viaf = \"\"\n",
    "    for b in oclc_a_list:\n",
    "        if last_name(author) in b['name']:\n",
    "            candidate = b['viaf']\n",
    "            print first_name(author)\n",
    "            if first_name(author) in b['name']:\n",
    "                viaf = candidate\n",
    "    if viaf == \"\":\n",
    "        viaf = candidate\n",
    "    return viaf\n",
    "\n",
    "data = get_oclc_data(\"0140024034\")\n",
    "print data\n",
    "print data['holdings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<addinfourl at 139826553309448 whose fp = <socket._fileobject object at 0x7f2be80891d0>>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "['823.91', '823.912', '820', 'FIC', '823.3', 'Unclassified']\n",
      "{'ddc': [{'percent': '70.82758', 'label': '823.91'}, {'percent': '21.310345', 'label': '823.912'}, {'percent': '0.5862069', 'label': '820'}, {'percent': '0.1724138', 'label': 'FIC'}, {'percent': '0.03448276', 'label': '823.3'}, {'percent': '7.0689654', 'label': 'Unclassified'}], 'holdings': '2873', 'subjects': [{'fast_id': '1204289', 'subject': 'France'}, {'fast_id': '1354514', 'subject': 'Revolution (France : 1789-1799)'}, {'fast_id': '943191', 'subject': 'Glass manufacture'}, {'fast_id': '19563', 'subject': 'Louis XVII, of France, 1785-1795'}], 'oclc_id': '20377499', 'authors': [{'viaf': '24600806', 'name': 'Du Maurier, Daphne, 1907-1989'}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_oclc_data(isbn):\n",
    "    url = oclc_base +\"isbn=\"+isbn\n",
    "    xml = url_to_x(url)\n",
    "    print type(xml)\n",
    "    authors = extract_authors(xml) #returns a list of dicts of form {'name':'author_name','viaf':'viaf_id'}\n",
    "    print type(xml)\n",
    "    subjects = extract_subjects(xml) #returns a list of dicts of form {'subject':'subject_name','fast_id':'fast_id'}\n",
    "    ddc = extract_ddc(xml) #returns a list of dicts of form {'label':'ddc_label', 'percent':'percent_of_entries_w_label'}\n",
    "    oclc_id = extract_oid(xml)\n",
    "    holdings = extract_holdings(xml)\n",
    "    return {'authors':authors,'subjects':subjects,'ddc':ddc,'oclc_id':oclc_id,'holdings':holdings}\n",
    "\n",
    "def extract_oid(oclc):\n",
    "    work = oclc.find('{http://classify.oclc.org}work')\n",
    "    oid = \"\"\n",
    "    if work is not None:\n",
    "        oid = work.get('owi')\n",
    "    return oid\n",
    "\n",
    "\n",
    "def extract_holdings(oclc):\n",
    "    work = oclc.find('{http://classify.oclc.org}work')\n",
    "    holdings = 0\n",
    "    if work is not None:\n",
    "        holdings = work.get('holdings')\n",
    "    return holdings\n",
    "\n",
    "def extract_authors(oclc):\n",
    "    oclc_a = oclc.find('{http://classify.oclc.org}authors')\n",
    "    author_arr = []\n",
    "    if oclc_a is not None:\n",
    "        for author in oclc_a:\n",
    "            author_arr.append({\"name\":author.text,\"viaf\":author.get(\"viaf\")})\n",
    "    return author_arr\n",
    "\n",
    "def extract_subjects(oclc):\n",
    "    r = oclc.find('{http://classify.oclc.org}recommendations')\n",
    "    subject_arr = []\n",
    "    if r is not None:\n",
    "        fast = r.find('{http://classify.oclc.org}fast')\n",
    "        if fast is not None:\n",
    "            oclc_s = fast.find('{http://classify.oclc.org}headings')\n",
    "            for subject in oclc_s:\n",
    "                subject_arr.append({\"subject\":subject.text,\"fast_id\":subject.get(\"ident\")})\n",
    "            return subject_arr\n",
    "\n",
    "def extract_ddc(oclc):\n",
    "    r = oclc.find('{http://classify.oclc.org}recommendations')\n",
    "    ddc_ls = []\n",
    "    if r is not None:\n",
    "        ddc_summary = r.find('{http://classify.oclc.org}ddc')\n",
    "        if ddc_summary is not None:\n",
    "            graph_url = ddc_summary.find('{http://classify.oclc.org}graph').text\n",
    "            ddc_ls = parse_graph_url(graph_url)\n",
    "    return ddc_ls\n",
    "\n",
    "def get_percentages(url):\n",
    "    nurl = url.split(\"chd=t:\")\n",
    "    nurl = nurl[1].split(\"&\")\n",
    "    parr = nurl[0].split(\",\")\n",
    "    return parr\n",
    "\n",
    "def get_labels(url):\n",
    "    nurl = url.split(\"chdl=\")\n",
    "    larr = nurl[1].split(\"|\")\n",
    "    print larr\n",
    "    return larr\n",
    "\n",
    "def parse_graph_url(gurl):\n",
    "    p = get_percentages(gurl)\n",
    "    l = get_labels(gurl)\n",
    "    target = []\n",
    "    i = 0\n",
    "    for label in l:\n",
    "        target.append({\"label\":label,\"percent\":p[i]})\n",
    "        i = i+1\n",
    "    return target\n",
    "\n",
    "data = get_oclc_data(\"0140024034\")\n",
    "print data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FINAL VERDICT', ['Adela Rogers St. Johns'])\n"
     ]
    }
   ],
   "source": [
    "sample_title_auth = commasv[2][2]\n",
    "#print sample_title_auth\n",
    "\n",
    "#index into phrase to skip \" by\"\n",
    "auth_i = 4\n",
    "\n",
    "def title_author_pair(data_str):\n",
    "    split_str = data_str.split(',')\n",
    "    title = \"\"\n",
    "    authors = []\n",
    "    i=0\n",
    "    for phrase in split_str:\n",
    "        if i == 0:\n",
    "            title = phrase\n",
    "        else:\n",
    "            if phrase.isupper():\n",
    "                title = title + \", \"+phrase\n",
    "            else:\n",
    "                author_ph = phrase[auth_i:]\n",
    "                if \" and \" in author_ph:\n",
    "                    author_arr = author_ph.split(\" and \")\n",
    "                    for author in author_arr:\n",
    "                        if author[len(author)-1]=='.':\n",
    "                            author = author[:len(author)-1] # strip trailing period\n",
    "                        authors.append(author)\n",
    "                else:\n",
    "                    author = author_ph\n",
    "                    if author[len(author)-1]=='.':\n",
    "                        author = author[:len(author)-1] # strip trailing period\n",
    "                    authors.append(author)\n",
    "        i = i+1\n",
    "    return (title,authors)\n",
    "        \n",
    "print title_author_pair(sample_title_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RAISE HIGH THE ROOF BEAM,  CARPENTERS', ['J.D. Salinger'])\n",
      "('SEVEN DAYS IN MAY', ['Fletcher Knebel', 'Charles W. Bailey II'])\n",
      "('THE GLASS BLOWERS', ['Daphne du Maurier'])\n",
      "('THE SAND PEBBLES', ['Richard McKenna'])\n",
      "('THE MOONFLOWER VINE', ['Jetta Carleton'])\n",
      "('THE MOONSPINNERS', ['Mary Stewart'])\n",
      "('GRANDMOTHER AND THE PRIESTS', ['Taylor Caldwell'])\n",
      "('FAIL-SAFE', ['Eugene Burdick', 'Harvey Wheeler'])\n",
      "('TRIUMPH', ['Philip Wylie'])\n",
      "('THE CENTAUR', ['John Updike'])\n"
     ]
    }
   ],
   "source": [
    "for row in commasv:\n",
    "    print(title_author_pair(row[2]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data Collection and Storage\n",
    "\n",
    "Store all data as we go through as a table (or look into pandas dataframe?). Each row is a BestSellers row and is formatted:\n",
    "\n",
    "* date -- date\n",
    "* title -- string\n",
    "* author(s) -- arr[string]\n",
    "* isbn_list -- arr[int]\n",
    "* author_wiki_dat_id -- int\n",
    "* author_gender(s) -- arr[string]\n",
    "\n",
    "Maybe if there are too few ISBN matches for a book I should flag it for manual tagging? How few is too few? Will have to experiment.\n",
    "\n",
    "Also want to store running dictionaries of these values so I don't need to call the function for the repeat appearances:\n",
    "\n",
    "* {(Title,Author):[isbn_list, gender]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ISBN from Title/Author Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api-2445581351187.apicast.io:443/search?app_key=62f7cedf62afa7006026634aaadce211&app_id=7f7512d5&t=Potatoes\n",
      "http://isbndb.com/api/books.xml?access_key=1DR9S9TA&index1=title&value1=Potatoes\n"
     ]
    }
   ],
   "source": [
    "%run \"key.py\"\n",
    "\n",
    "suffixes = ['CPA', 'CSC', 'CSJ', 'DC', 'DD', 'DDS', 'DMD', 'DO', 'DVM', 'EDD', 'ESQ', 'II', 'III', \n",
    "            'IV', 'INC', 'JD', 'JR', 'LLD', 'LTD', 'MD', 'OD', 'OSB', 'PC', 'PE', 'PHD', 'RET', \n",
    "            'RGS', 'RN', 'RNC', 'SHCJ', 'SJ', 'SNJM', 'SR', 'SSMO', 'USA', 'USAF', 'USAFR', 'USAR', \n",
    "            'USCG', 'USMC', 'USMCR', 'USN', 'USNR']\n",
    "\n",
    "prefixes = []\n",
    "\n",
    "digits = ['1','2','3','4','5','6','7','8','9','0']\n",
    "symbol_dict = {'%':'percent','$':'dollar', '1/2':'half'}\n",
    "\n",
    "isbn_plus_base_url = \"https://api-2445581351187.apicast.io:443\"\n",
    "plus_key = isbn_plus_key\n",
    "app_id = \"7f7512d5\"\n",
    "search_plus = \"/search?app_key=\"+plus_key+\"&app_id=\"+app_id+\"&t=\"\n",
    "print isbn_plus_base_url+search_plus+\"Potatoes\"\n",
    "alph = re.compile('[^a-zA-Z]')\n",
    "\n",
    "db_key = isbn_db_key\n",
    "isbn_db_base = \"http://isbndb.com/api\"\n",
    "search_db = \"/books.xml?access_key=\"+db_key+\"&index1=title&value1=\"\n",
    "print isbn_db_base+search_db+\"Potatoes\"\n",
    "\n",
    "def convert_to_search(name):\n",
    "    return_string = \"\"\n",
    "    last_ch = \" \"\n",
    "    for ch in name:\n",
    "        if (ch == \" \"):\n",
    "            if (last_ch != \".\"):\n",
    "                return_string = return_string + \"+\"\n",
    "        else:\n",
    "            if ch == \".\":\n",
    "                return_string = return_string +\".+\"\n",
    "            else:\n",
    "                return_string = return_string+ch\n",
    "        last_ch = ch\n",
    "    return return_string\n",
    "\n",
    "def url_to_xml(url):\n",
    "    req = urllib2.Request(url)\n",
    "    req.add_header('User-agent', 'Mozilla 5.10')\n",
    "    res = urllib2.urlopen(req)\n",
    "    print res\n",
    "    data = xml.etree.ElementTree.parse(res).getroot()[0]\n",
    "    for book in data.findall('BookData'):\n",
    "        isbn = book.get('isbn')\n",
    "        title = book.find('Title').text\n",
    "        author = book.find('AuthorsText').text\n",
    "        print(isbn,title,author)\n",
    "    return data\n",
    "\n",
    "def suffix(phrase):\n",
    "    norm_phrase = phrase.replace(',',\"\").upper()\n",
    "    if norm_phrase in suffixes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def prefix(phrase):\n",
    "    norm_phrase = phrase.replace(',',\"\").upper()\n",
    "    if norm_phrase in prefixes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def last_name_recursive(name,last_index):\n",
    "    if last_index == 0:\n",
    "        return \"\"\n",
    "    last_phrase = name[last_index]\n",
    "    if not suffix(last_phrase):\n",
    "        return last_phrase\n",
    "    else:\n",
    "        return last_name_recursive(name, last_index-1)\n",
    "\n",
    "def last_name(name):\n",
    "    names = name.split(\" \")\n",
    "    last_index = len(names)-1\n",
    "    last = last_name_recursive(names,last_index)\n",
    "    return last\n",
    "\n",
    "def first_name(name):\n",
    "    names = name.split(\" \")\n",
    "    return names[0]\n",
    "\n",
    "def strip_punct(text):\n",
    "    return alph.sub('', text)\n",
    "\n",
    "def has_numbers(text):\n",
    "    for digit in digits:\n",
    "        if digit in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_symbols(text):\n",
    "    for symbol in symbol_dict:\n",
    "        if symbol in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def norm_text(text):\n",
    "    return strip_punct(text).lower()\n",
    "\n",
    "def is_book(booxml, title, authors):\n",
    "    xml_title = booxml.find('Title').text\n",
    "    norm_xml_title = norm_text(xml_title)\n",
    "    norm_title = norm_text(title)\n",
    "    if(norm_xml_title in norm_title) or (norm_title in norm_xml_title):\n",
    "        xml_authors = booxml.find('AuthorsText').text\n",
    "        if xml_authors is None:\n",
    "            return False\n",
    "        for author in authors:\n",
    "            if norm_text(author) in norm_text(xml_authors):\n",
    "                print \"Adding ISBN! \"+xml_title+\" by \"+xml_authors\n",
    "                return True\n",
    "            xml_names = []\n",
    "            for xmla in xml_authors.split(\" \"):\n",
    "                norm_text(xmla)\n",
    "            for author in authors:\n",
    "                if norm_text(last_name(author)) in xml_authors.split(\" \"):\n",
    "                    print \"Adding ISBN! \"+xml_title+\" by \"+xml_authors\n",
    "                    return True        \n",
    "        return False\n",
    "\n",
    "def get_isbns(title,authors):\n",
    "    isbns = set()\n",
    "    search_t = convert_to_search(title)\n",
    "    url = isbn_db_base+search_db+search_t\n",
    "#    print row[0].year\n",
    "    data = url_to_xml(url)\n",
    "    for book in data:\n",
    "        if (is_book(book,title,authors)):\n",
    "            isbns.add(book.get('isbn'))            \n",
    "    return isbns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bailey\n"
     ]
    }
   ],
   "source": [
    "print last_name('Charles W. Bailey II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAVELS WITH CHARLEY', ['John Steinbeck'])\n",
      "<addinfourl at 139723408233032 whose fp = <socket._fileobject object at 0x7f13e429af50>>\n",
      "('1405509163', 'Travels with Charley', None)\n",
      "('043474011X', 'Travels with Charley', 'John Steinbeck')\n",
      "('0783887914', 'Travels with Charley', 'John Steinbeck')\n",
      "('0330201107', 'Travels with Charley', 'John Steinbeck')\n",
      "('0808588761', 'Travels With Charley', None)\n",
      "('0140053204', 'Travels with Charley', 'John Steinbeck')\n",
      "('0142000701', 'Travels with Charley', 'John Steinbeck')\n",
      "('1560773448', 'Travels With Charley', 'Judie Henson, Sheryl Lee Hinman, ')\n",
      "('0788734822', 'Travels with Charley In Search of America', 'John Steinbeck, Ron McLarty (Narrator)')\n",
      "('0141186100', 'Travels with Charley in search of America', 'John Steinbeck; with an introduction by Jay Parini')\n",
      "Adding ISBN! Travels with Charley by John Steinbeck\n",
      "Adding ISBN! Travels with Charley by John Steinbeck\n",
      "Adding ISBN! Travels with Charley by John Steinbeck\n",
      "Adding ISBN! Travels with Charley by John Steinbeck\n",
      "Adding ISBN! Travels with Charley by John Steinbeck\n",
      "Adding ISBN! Travels with Charley In Search of America by John Steinbeck, Ron McLarty (Narrator)\n",
      "Adding ISBN! Travels with Charley in search of America by John Steinbeck; with an introduction by Jay Parini\n",
      "('HAPPINESS IS A WARM PUPPY', ['Charles M. Schulz'])\n",
      "<addinfourl at 139723408797208 whose fp = <socket._fileobject object at 0x7f13e429af50>>\n",
      "('0345348826', 'Happiness is a warm puppy', 'by Charles M. Schulz')\n",
      "('0886873118', 'Happiness is a warm puppy', 'by Charles M. Schulz')\n",
      "('0001953206', 'Happiness is - a warm puppy', 'by Charles M. Schulz')\n",
      "('0915696754', 'Happiness is a Warm Puppy', 'Charles M. Schulz, ')\n",
      "('0915696134', 'Happiness is... a warm puppy', 'by Charles M. Schulz')\n",
      "('1561484393', \"Here's a Happy Puppy\", 'Colin Hawkins, ')\n",
      "('1604332468', 'Happiness is a Warm Puppy: The Seedling Edition', 'Charles M. Schulz, ')\n",
      "('0727806653', 'Happiness is a warm corpse', '[compiled by] Alfred Hitchock.')\n",
      "('1933662077', 'Happiness is a Warm Puppy', 'Charles M. Schulz, ')\n",
      "('1844540316', 'Chopper 4: Happiness Is a Warm Gun', 'Mark Brandon Read, ')\n",
      "Adding ISBN! Happiness is a warm puppy by by Charles M. Schulz\n",
      "Adding ISBN! Happiness is a warm puppy by by Charles M. Schulz\n",
      "Adding ISBN! Happiness is - a warm puppy by by Charles M. Schulz\n",
      "Adding ISBN! Happiness is a Warm Puppy by Charles M. Schulz, \n",
      "Adding ISBN! Happiness is... a warm puppy by by Charles M. Schulz\n",
      "Adding ISBN! Happiness is a Warm Puppy: The Seedling Edition by Charles M. Schulz, \n",
      "Adding ISBN! Happiness is a Warm Puppy by Charles M. Schulz, \n",
      "('FINAL VERDICT', ['Adela Rogers St. Johns'])\n",
      "<addinfourl at 139723408067688 whose fp = <socket._fileobject object at 0x7f13e429a6d0>>\n",
      "('0373507763', 'Final verdict', None)\n",
      "('0451151267', 'Final Verdict', 'D. Kincaid, ')\n",
      "('0451049055', 'Final Verdict', 'St. Johns, ')\n",
      "('0965542939', 'Final Verdict', 'Marianne Woolbert, ')\n",
      "('0007292872', 'Maxwell: The Final Verdict', None)\n",
      "('0743422295', 'Until the final verdict', None)\n",
      "('0551031247', 'The final verdict', 'Gillian Powe')\n",
      "('0671043773', 'Final Verdict', 'Vincent Bugliosi, ')\n",
      "('0399150420', 'Final verdict', 'Sheldon Siegel')\n",
      "('037030571X', 'Wallace, the final verdict', 'Roger Wilkes')\n",
      "('THE WHOLE TRUTH AND NOTHING BUT', ['Hedda Hopper'])\n",
      "<addinfourl at 139723408154352 whose fp = <socket._fileobject object at 0x7f13e429aa50>>\n",
      "('0731021789', 'The truth, the whole truth and nothing but the truth?', 'Public Accounts Committee')\n",
      "('0612593797', 'The truth, whole truth, and nothing but the truth', None)\n",
      "('0398056560', 'The truth, the whole truth and nothing but', 'by D. W. Reynolds')\n",
      "('0710010044', 'Nothing but the Truth', None)\n",
      "('0606055185', 'Nothing but the Truth', 'Avi, ')\n",
      "('0099268663', 'Nothing But the Truth', 'Samuel Lock, ')\n",
      "('0814751741', 'Nothing but the truth', 'Steven Lubet')\n",
      "('0814751733', 'Nothing but the truth', 'Steven Lubet')\n",
      "('0446530204', '25 to life', 'Leslie Crocker Snyder with Tom Shachtman')\n",
      "('0955023017', 'Church and sabbath', 'Martin H. Simmonds.')\n",
      "('O YE JIGS & JULEPS!', ['Virginia Cary Hudson'])\n",
      "<addinfourl at 139723408277872 whose fp = <socket._fileobject object at 0x7f13e429ab50>>\n",
      "('0020404808', 'O ye jigs & juleps!', 'by Virginia Cary Hudson; illustrated by Karla Kuskin')\n",
      "('0876023154', 'O ye jigs and juleps', 'text and lyrics by Don Musselman; music by Sim Broadfield')\n",
      "('0884861406', 'O Ye Jigs and Juleps!', 'Virginia Cary Hudson, ')\n",
      "('0415209870', \"The psychology of children's drawings\", 'Helga Eng')\n",
      "('0108733157', 'Pensions Bill [H. L.]', None)\n",
      "('0751371912', 'Summerhouse', 'Laurence Anholt; illustrated by Lynne Russell')\n",
      "('1582293031', 'Rescued By the Cross', 'Ken Freeman, ')\n",
      "('1873437080', 'Between the Jigs and the Reels', 'Caoimhin Mac Aoidh, Proinnsios O Duigneain (Editor)')\n",
      "('1857200276', \"O'Neill's 1001 Jigs, Reels, Hornpipes, Airs and Marches\", \"Francis O'Neill (Editor)\")\n",
      "('0071405569', 'Jigs and fixtures', 'P. H. Joshi; foreword and edited by Robert O. Parmley')\n",
      "Adding ISBN! O ye jigs & juleps! by by Virginia Cary Hudson; illustrated by Karla Kuskin\n",
      "('THE FIRE NEXT TIME', ['James Baldwin'])\n",
      "<addinfourl at 139723408057408 whose fp = <socket._fileobject object at 0x7f13e422cc50>>\n",
      "('0440025427', 'The Fire Next Time', 'James Baldwin, ')\n",
      "('0140182756', 'The fire next time', 'James Baldwin')\n",
      "('0679601511', 'The fire next time', 'James Baldwin')\n",
      "('0440325420', 'The fire next time', 'James Baldwin')\n",
      "('0140022376', 'The fire next time', 'James Baldwin')\n",
      "('1582880824', 'Go Tell It On The Mountain The Fire Next Time If Beale Street Could Talk', None)\n",
      "('0801488907', 'No fire next time', 'Patrick D. Joyce')\n",
      "('0801439418', 'No fire next time', 'Patrick D. Joyce')\n",
      "('0531003124', 'The Fire Next Time', 'James A. Baldwin, ')\n",
      "('1605149586', 'The Fire Next Time', 'James Baldwin, ')\n",
      "Adding ISBN! The Fire Next Time by James Baldwin, \n",
      "Adding ISBN! The fire next time by James Baldwin\n",
      "Adding ISBN! The fire next time by James Baldwin\n",
      "Adding ISBN! The fire next time by James Baldwin\n",
      "Adding ISBN! The fire next time by James Baldwin\n",
      "Adding ISBN! The Fire Next Time by James Baldwin, \n",
      "('SILENT SPRING', ['Rachel Carson'])\n",
      "<addinfourl at 139723408058272 whose fp = <socket._fileobject object at 0x7f13e422ce50>>\n",
      "('0140273719', 'Silent spring', 'Rachel Carson')\n",
      "('0606056009', 'SILENT SPRING', 'RACHEL CARSON, ')\n",
      "('0449231410', 'Since Silent Spring', 'Frank Graham, ')\n",
      "('0044901496', 'Since Silent Spring', 'Frank Graham, ')\n",
      "('1593757638', \"Rachel Carson's Silent Spring\", None)\n",
      "('0395077532', 'Since silent spring', None)\n",
      "('053002988X', 'Since Silent spring', None)\n",
      "('0449200795', 'Silent spring', 'by Rachel Carson')\n",
      "('4102074015', 'Silent Spring', 'Rachel Carson, ')\n",
      "('0449231259', 'Silent spring', 'by Rachel Carson')\n",
      "Adding ISBN! Silent spring by Rachel Carson\n",
      "Adding ISBN! SILENT SPRING by RACHEL CARSON, \n",
      "Adding ISBN! Silent spring by by Rachel Carson\n",
      "Adding ISBN! Silent Spring by Rachel Carson, \n",
      "Adding ISBN! Silent spring by by Rachel Carson\n",
      "('MY LIFE IN COURT', ['Louis Nizer'])\n",
      "<addinfourl at 139723408067976 whose fp = <socket._fileobject object at 0x7f13e422ccd0>>\n",
      "('0515027642', 'My Life in Court', 'Louis Nizer, ')\n",
      "('156849145X', 'My Life in Court', 'Louis Nizer, ')\n",
      "('1430462566', 'My Life In Court', 'Louis Nizer, ')\n",
      "('9997500172', 'My Life in Court', 'Louis Nizer, ')\n",
      "('1163136182', 'My Life In Court', 'Louis Nizer, ')\n",
      "('0140053913', \"In my father's court\", 'Isaac Bashevis Singer')\n",
      "('0099422662', \"In my father's court\", 'Isaac Bashevis Singer.')\n",
      "('184737543X', 'My Life: Queen of the Court', None)\n",
      "('0374505926', \"In my father's court\", 'Isaac Bashevis Singer')\n",
      "('0396072070', 'Court on Court, a Life in Tennis', 'Margaret Smith, Court, ')\n",
      "Adding ISBN! My Life in Court by Louis Nizer, \n",
      "Adding ISBN! My Life in Court by Louis Nizer, \n",
      "Adding ISBN! My Life In Court by Louis Nizer, \n",
      "Adding ISBN! My Life in Court by Louis Nizer, \n",
      "Adding ISBN! My Life In Court by Louis Nizer, \n",
      "('POINTS OF MY COMPASS', ['E.B. White'])\n",
      "<addinfourl at 139723407844488 whose fp = <socket._fileobject object at 0x7f13e422cb50>>\n",
      "('0060145854', 'The Points of My Compass', 'E.B. White, ')\n",
      "('1419633392', 'Points On My Compass', 'Phyllis Henry-Jordan, ')\n",
      "('095191006X', 'The compass points of loss', 'Jack Hill.')\n",
      "('0065160118', 'Charting compass points', 'Walter B. Barbe, et al')\n",
      "('0708312209', 'Compass points', 'selected by Janet Davies')\n",
      "('1449032796', 'Eight Points of the Compass', 'Don Levin, ')\n",
      "('0890970173', 'Only one point of the compass', 'Marion Marsh Brown and Ruth Crone')\n",
      "('0330023748', 'The fifth point of the compass', 'by Miles Tripp')\n",
      "('0375402462', 'Compass points', 'Edward Hoagland')\n",
      "('0585274029', 'Compass points', 'selected by Janet Davies')\n",
      "Adding ISBN! The Points of My Compass by E.B. White, \n",
      "('THE FALL OF THE DYNASTIES', ['Edmond Taylor'])\n",
      "<addinfourl at 139723408280896 whose fp = <socket._fileobject object at 0x7f13e422ccd0>>\n",
      "('088029390X', 'The fall of the dynasties', None)\n",
      "('034060087X', 'Mafia dynasty', 'John H. Davis')\n",
      "('1435104080', 'Chinese Emperors From the Xia Dynasty to the Fall of the Qing Dynasty', 'Ma Yan, ')\n",
      "('077101015X', 'The dynasty', 'John J. Barr')\n",
      "('0750932708', 'Coxinga and the fall of the Ming dynasty', 'Jonathan Clements')\n",
      "('0812240367', 'Almost a dynasty', 'William C. Kashatus')\n",
      "('0060163577', 'Mafia dynasty', 'John H. Davis')\n",
      "('0061091847', 'Mafia dynasty', 'John H. Davis')\n",
      "('0806117419', 'The glory and fall of the Ming dynasty', 'by Albert Chan')\n",
      "('7535437214', 'The Han Dynasty Fall of the Qin Dynasty and Rise of the Han Dynasty and Liu Bang s Ascending to the Throne', 'Lao Li Chuan Chang, ')\n",
      "[1963, 'TRAVELS WITH CHARLEY', ['John Steinbeck'], set(['0142000701', '0788734822', '043474011X', '0140053204', '0330201107', '0141186100', '0783887914'])]\n",
      "[1963, 'HAPPINESS IS A WARM PUPPY', ['Charles M. Schulz'], set(['1604332468', '0915696134', '1933662077', '0915696754', '0001953206', '0886873118', '0345348826'])]\n",
      "[1963, 'FINAL VERDICT', ['Adela Rogers St. Johns'], set([])]\n",
      "[1963, 'THE WHOLE TRUTH AND NOTHING BUT', ['Hedda Hopper'], set([])]\n",
      "[1963, 'O YE JIGS & JULEPS!', ['Virginia Cary Hudson'], set(['0020404808'])]\n",
      "[1963, 'THE FIRE NEXT TIME', ['James Baldwin'], set(['0440025427', '0440325420', '0140182756', '1605149586', '0679601511', '0140022376'])]\n",
      "[1963, 'SILENT SPRING', ['Rachel Carson'], set(['0606056009', '0449200795', '0140273719', '4102074015', '0449231259'])]\n",
      "[1963, 'MY LIFE IN COURT', ['Louis Nizer'], set(['1430462566', '0515027642', '156849145X', '1163136182', '9997500172'])]\n",
      "[1963, 'POINTS OF MY COMPASS', ['E.B. White'], set(['0060145854'])]\n",
      "[1963, 'THE FALL OF THE DYNASTIES', ['Edmond Taylor'], set([])]\n"
     ]
    }
   ],
   "source": [
    "def process_bs_list(best_sellers, year):\n",
    "    target = []\n",
    "    for row in best_sellers:\n",
    "        title_author = title_author_pair(row[2])\n",
    "        print str(title_author)\n",
    "        isbns = []\n",
    "        if has_symbols(title_author[0]) or has_numbers(title_author[0]):\n",
    "            manual_titles.append(title_author)\n",
    "        else:\n",
    "            stritle_author = str(title_author)\n",
    "            if stritle_author not in done_dict:\n",
    "                isbns = get_isbns(title_author[0],title_author[1])\n",
    "                if len(isbns) == 0:\n",
    "                    manual_titles.append(title_author)\n",
    "                done_dict[stritle_author] = isbns\n",
    "            else:\n",
    "                isbns = done_dict[stritle_author]\n",
    "        target.append([year,title_author[0],title_author[1],isbns])\n",
    "    return target\n",
    "                \n",
    "for x in process_bs_list(commasv,1963):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TRIUMPH', ['Philip Wylie'])]\n"
     ]
    }
   ],
   "source": [
    "def process_bs_batch(batch):\n",
    "    batch_target = []\n",
    "    for ls in batch:\n",
    "        process_bs_list(ls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Gender Data from Author Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_name_to_id = \"https://www.wikidata.org/w/api.php?action=wbsearchentities&language=en&format=json&search=\"\n",
    "wiki_id_to_data = \"https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=\"\n",
    "gender_prop_id = \"P21\"\n",
    "wiki_gender_hash = {\"Q6581097\":\"male\", \"Q6581072\":\"female\",\"Q1052281\":\"transf\",\"Q2449503\":\"transm\",\"Q1097630\":\"intersex\"}\n",
    "\n",
    "import urllib2\n",
    "import json\n",
    "\n",
    "def url_to_data( url ):\n",
    "    req = urllib2.Request(url)\n",
    "    req.add_header('User-agent', 'Mozilla 5.10')\n",
    "    res = urllib2.urlopen(req)\n",
    "    data = json.load(res)\n",
    "    return data\n",
    "\n",
    "def same_gender(id_list):\n",
    "    id_0 = id_list[0]\n",
    "    for i in id_list[1:]:\n",
    "        if gender_from_id(id_0) != gender_from_id(i):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "## This needs to disambiguate -- does it need to pull more information by id?\n",
    "## Let's do it\n",
    "def disambiguate(entity_data, name):\n",
    "    entities = []\n",
    "    for entity in entity_data:\n",
    "        if 'description' in entity:\n",
    "            desc = entity['description'].lower()\n",
    "            ent_id = entity['id']\n",
    "            if ('novel' in desc) or ('write' in desc) or ('auth' in desc) or ('cartoo' in desc) or ('journ' in desc) or ('comic' in desc):\n",
    "                entities.append((ent_id,desc))\n",
    "    if len(entities)==0:\n",
    "        print \"No novelists, writers, authors, cartoonists, journalists or comics named \"+name\n",
    "        manual_genders.add(name)\n",
    "        for x in entity_data:\n",
    "            print x\n",
    "    return entities\n",
    "\n",
    "def get_wiki_id(name):\n",
    "    search_term = convert_to_search(name)\n",
    "    url = wiki_name_to_id + search_term\n",
    "    data = url_to_data(url)['search']\n",
    "    if data == []:\n",
    "        return [-1]\n",
    "    dis_data = disambiguate(data,name)\n",
    "    if dis_data == []:\n",
    "        return [-1]\n",
    "    i = []\n",
    "    for entity in dis_data:\n",
    "        i.append(entity[0])\n",
    "    return i\n",
    "\n",
    "def gender_from_id(auth_id):\n",
    "    url = wiki_id_to_data + auth_id\n",
    "    print url\n",
    "    claims = url_to_data(url)['entities'][str(auth_id)]['claims']['P21']\n",
    "    gender_arr =[]\n",
    "    for claim in claims:\n",
    "        if claim['mainsnak']['datavalue']['value'] is not None:\n",
    "            gender_id = claim['mainsnak']['datavalue']['value']['id']\n",
    "            gender_arr.append(wiki_gender_hash[gender_id])\n",
    "    if len(gender_arr)>1:\n",
    "        gender = max_value(gender_arr) ## FIX THIS\n",
    "    else:\n",
    "        gender = gender_arr[0]\n",
    "    return gender\n",
    "\n",
    "\n",
    "#def book_to_key_facts(book_data):\n",
    "\n",
    "def author_to_gender(author_name):\n",
    "    gender = \"\"\n",
    "    author_id = []\n",
    "    author_id = get_wiki_id(author_name)\n",
    "    print author_id\n",
    "    if author_id[0] == -1:\n",
    "        print \"Unable to find \"+author_name+\" in database\"\n",
    "        return \"unknown\"\n",
    "    if len(author_id)>1:\n",
    "        print \"More than one writer by the name \"+author_name\n",
    "        if(same_gender(author_id)):\n",
    "            gender = gender_from_id(author_id[0])\n",
    "    else:\n",
    "        gender = gender_from_id(author_id[0])\n",
    "        return gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FUCK WIKIDATA, LIBRARIES GOT ME COVERED\n",
    "\n",
    "Look up book genres by ISBN using this tool:\n",
    "\n",
    "https://platform.worldcat.org/api-explorer/apis/Classify\n",
    "\n",
    "classify.oclc.org/classify2/Classify?oclc=57358293&summary=true\n",
    "\n",
    "I could also apparently use this to GET isbns -- I'll try it for a table and compare.\n",
    "\n",
    "This returns authors per book with their names and VIAF id, which I can look up here:\n",
    "\n",
    "https://platform.worldcat.org/api-explorer/apis/VIAF\n",
    "https://platform.worldcat.org/api-explorer/apis/VIAF/AuthorityCluster/Identify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Q15637611']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q15637611\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "print author_to_gender(\"Virginia Cary Hudson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Q39212', u'Q5559244']\n",
      "More than one writer by the name John Steinbeck\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q39212\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q5559244\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q39212\n",
      "John Steinbeck was a male\n",
      "[u'Q298920']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q298920\n",
      "Charles M. Schulz was a male\n",
      "[u'Q353774']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q353774\n",
      "Adela Rogers St. Johns was a female\n",
      "No novelists, writers, authors, cartoonists, journalists or comics named Hedda Hopper\n",
      "{u'pageid': 262584, u'description': u'Actress, gossip columnist, radio personality', u'title': u'Q271324', u'concepturi': u'http://www.wikidata.org/entity/Q271324', u'label': u'Hedda Hopper', u'url': u'//www.wikidata.org/wiki/Q271324', u'id': u'Q271324', u'match': {u'text': u'Hedda Hopper', u'type': u'label', u'language': u'en'}}\n",
      "[-1]\n",
      "Unable to find Hedda Hopper in database\n",
      "Hedda Hopper was a unknown\n",
      "[u'Q15637611']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q15637611\n",
      "Virginia Cary Hudson was a female\n",
      "[u'Q273210', u'Q15976232', u'Q18529778']\n",
      "More than one writer by the name James Baldwin\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q273210\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q15976232\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q273210\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q18529778\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q273210\n",
      "James Baldwin was a male\n",
      "No novelists, writers, authors, cartoonists, journalists or comics named Rachel Carson\n",
      "{u'pageid': 103533, u'description': u'American marine biologist and conservationist', u'title': u'Q100948', u'concepturi': u'http://www.wikidata.org/entity/Q100948', u'label': u'Rachel Carson', u'url': u'//www.wikidata.org/wiki/Q100948', u'id': u'Q100948', u'match': {u'text': u'Rachel Carson', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 29871282, u'title': u'Q28173403', u'concepturi': u'http://www.wikidata.org/entity/Q28173403', u'label': u'Rachel Carson', u'url': u'//www.wikidata.org/wiki/Q28173403', u'id': u'Q28173403', u'match': {u'text': u'Rachel Carson', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 7183370, u'description': u'Wikipedia disambiguation page', u'title': u'Q7279182', u'concepturi': u'http://www.wikidata.org/entity/Q7279182', u'label': u'Rachel Carson', u'url': u'//www.wikidata.org/wiki/Q7279182', u'id': u'Q7279182', u'match': {u'text': u'Rachel Carson', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 737099, u'description': u'award', u'title': u'Q784097', u'concepturi': u'http://www.wikidata.org/entity/Q784097', u'label': u'Rachel Carson Prize', u'url': u'//www.wikidata.org/wiki/Q784097', u'id': u'Q784097', u'match': {u'text': u'Rachel Carson Prize', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 2051353, u'description': u'Wikipedia disambiguation page', u'title': u'Q2125206', u'concepturi': u'http://www.wikidata.org/entity/Q2125206', u'label': u'Rachel Carson House', u'url': u'//www.wikidata.org/wiki/Q2125206', u'id': u'Q2125206', u'match': {u'text': u'Rachel Carson House', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 2051355, u'title': u'Q2125208', u'concepturi': u'http://www.wikidata.org/entity/Q2125208', u'label': u'Rachel Carson National Wildlife Refuge', u'url': u'//www.wikidata.org/wiki/Q2125208', u'id': u'Q2125208', u'match': {u'text': u'Rachel Carson National Wildlife Refuge', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 18571902, u'title': u'Q16968120', u'concepturi': u'http://www.wikidata.org/entity/Q16968120', u'label': u'Rachel Carson Award', u'url': u'//www.wikidata.org/wiki/Q16968120', u'id': u'Q16968120', u'match': {u'text': u'Rachel Carson Award', u'type': u'label', u'language': u'en'}}\n",
      "[-1]\n",
      "Unable to find Rachel Carson in database\n",
      "Rachel Carson was a unknown\n",
      "No novelists, writers, authors, cartoonists, journalists or comics named Louis Nizer\n",
      "{u'pageid': 6522048, u'description': u'American lawyer', u'title': u'Q6687903', u'concepturi': u'http://www.wikidata.org/entity/Q6687903', u'label': u'Louis Nizer', u'url': u'//www.wikidata.org/wiki/Q6687903', u'id': u'Q6687903', u'match': {u'text': u'Louis Nizer', u'type': u'label', u'language': u'en'}}\n",
      "[-1]\n",
      "Unable to find Louis Nizer in database\n",
      "Louis Nizer was a unknown\n",
      "[u'Q361617']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q361617\n",
      "E.B. White was a male\n",
      "[-1]\n",
      "Unable to find Edmond Taylor in database\n",
      "Edmond Taylor was a unknown\n"
     ]
    }
   ],
   "source": [
    "for row in commasv:\n",
    "    authors = title_author_pair(row[2])[1]\n",
    "    for author in authors:\n",
    "        gender = author_to_gender(author)\n",
    "        print author + \" was a \"+gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ISBNS & Author Name to Gender\n",
    "\n",
    "Use the VIAF api https://platform.worldcat.org/api-explorer/apis/VIAF/AuthorityCluster/GetDataInFormat\n",
    "\n",
    "# ISBNS to Subjects/Genres/DDC Category\n",
    "\n",
    "Use the OCLC classify api -- much better than goodreads! http://classify.oclc.org/classify2/api_docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.viaf.org/viaf/102403515/\n",
      "Male\n",
      "Male\n"
     ]
    }
   ],
   "source": [
    "VIAF = {\"Jane Austen\":\"102333412\",\"James Tiptree\":\"266704950\",\"Dan Brown\":\"102403515\",\"J.K. Rowling\":\"116796842\",\n",
    "        \"J.D. Salinger\":\"17092\",\"Chimamanda\":\"87194517\",\"Dostoyevski\":\"104023256\", \"Hedda Hopper\":\"52211425\"}\n",
    "headers= {\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.82 Safari/537.36\"}\n",
    "\n",
    "import urllib2\n",
    "import xml.etree.ElementTree\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "viaf_base = \"http://www.viaf.org/viaf/\"\n",
    "\n",
    "\n",
    "def get_gender_scrape(i):\n",
    "    url = viaf_base+str(i)+\"/\"\n",
    "    print url\n",
    "    data = requests.get(url).text\n",
    "    soup = BeautifulSoup(data,\"lxml\")\n",
    "    personal = soup.find('div',{'id':'personalinfo'})\n",
    "    h4s = personal.find('h4')\n",
    "    if len(h4s)<5:\n",
    "        return \"\"\n",
    "    #print type(h4s)\n",
    "    mt = []\n",
    "    i=0\n",
    "    for h in h4s:\n",
    "        mt.append(h)\n",
    "        #print \"element \"+str(i)+\": \"+str(h)\n",
    "        i = i+1\n",
    "    print mt[4]\n",
    "    return mt[4]\n",
    "\n",
    "print get_gender_scrape(VIAF[\"Dan Brown\"])\n",
    "\n",
    "#tree = html.fromstring(page.content)\n",
    "#print page.text\n",
    "#tags =  tree.xpath(\"//*[@id='personalinfo']/h4/span[class='langHi0']\")\n",
    "#print tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102403515\n",
      "http://www.viaf.org/viaf/102403515/\n",
      "Male\n",
      "Dan Brown is tagged as: Male\n",
      "116796842\n",
      "http://www.viaf.org/viaf/116796842/\n",
      "Female\n",
      "J.K. Rowling is tagged as: Female\n",
      "266704950\n",
      "http://www.viaf.org/viaf/266704950/\n",
      "Female\n",
      "James Tiptree is tagged as: Female\n",
      "104023256\n",
      "http://www.viaf.org/viaf/104023256/\n",
      "Male\n",
      "Dostoyevski is tagged as: Male\n",
      "52211425\n",
      "http://www.viaf.org/viaf/52211425/\n",
      "Female\n",
      "Hedda Hopper is tagged as: Female\n",
      "102333412\n",
      "http://www.viaf.org/viaf/102333412/\n",
      "Jane Austen is tagged as: \n",
      "17092\n",
      "http://www.viaf.org/viaf/17092/\n",
      "Male\n",
      "J.D. Salinger is tagged as: Male\n",
      "87194517\n",
      "http://www.viaf.org/viaf/87194517/\n",
      "Female\n",
      "Chimamanda is tagged as: Female\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for v in VIAF:\n",
    "    print VIAF[v]\n",
    "    print v+\" is tagged as: \"+str(get_gender_scrape(VIAF[v]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
