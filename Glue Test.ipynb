{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Getting Authors and Titles from Tabula-exported TSV Data\n",
    "\n",
    "The object: go from a list of tsv filenames (maybe I'll bin them by year?) to an array of [date, rank, weeks on list, title, author(s)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['March 17, 1963']\n",
      "1963-03-17 00:00:00\n",
      "[[datetime.datetime(1963, 3, 17, 0, 0), '1', 'TRAVELS WITH CHARLEY, by John Steinbeck.', '1', '32'], [datetime.datetime(1963, 3, 17, 0, 0), '2', 'HAPPINESS IS A WARM PUPPY, by Charles M. Schulz.', '2', '13'], [datetime.datetime(1963, 3, 17, 0, 0), '3', 'FINAL VERDICT, by Adela Rogers St. Johns.', '4', '27'], [datetime.datetime(1963, 3, 17, 0, 0), '4', 'THE WHOLE TRUTH AND NOTHING BUT, by Hedda Hopper.', '7', '2'], [datetime.datetime(1963, 3, 17, 0, 0), '5', 'O YE JIGS & JULEPS!, by Virginia Cary Hudson.', '3', '43'], [datetime.datetime(1963, 3, 17, 0, 0), '6', 'THE FIRE NEXT TIME, by James Baldwin', '6', '3'], [datetime.datetime(1963, 3, 17, 0, 0), '7', 'SILENT SPRING, by Rachel Carson.', '5', '24'], [datetime.datetime(1963, 3, 17, 0, 0), '8', 'MY LIFE IN COURT, by Louis Nizer.', '10', '68'], [datetime.datetime(1963, 3, 17, 0, 0), '9', 'POINTS OF MY COMPASS, by E.B. White.', '8', '5'], [datetime.datetime(1963, 3, 17, 0, 0), '10', 'THE FALL OF THE DYNASTIES, by Edmond Taylor.', '9', '2']]\n"
     ]
    }
   ],
   "source": [
    "f_filen = \"tabula-1963-03-17.tsv\"\n",
    "nf_filen = \"tabula-1963-03-17-nf.tsv\"\n",
    "#How far into the tsv file the data shows up...\n",
    "data_i = 2\n",
    "fields = ['rank','title+author','rank_last_week','weeks_on_list']\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def empty(row):\n",
    "    for r in row:\n",
    "        if r!=\"\":\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "def extract_date(datestr):\n",
    "    print datestr\n",
    "    date = datetime.strptime(datestr[0],'%B %d, %Y')\n",
    "    print date\n",
    "    return date\n",
    "\n",
    "##Indexes into row data_i of a tsv and then reads it into an array of arrays\n",
    "def read_tsv(name):\n",
    "    i = 0\n",
    "    arr = []\n",
    "    date = \"\"\n",
    "    with open(name) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if i ==0 :\n",
    "                date = extract_date([row[1]])\n",
    "            if ((i > data_i) & (not empty(row))):\n",
    "                arr.append([date]+row)\n",
    "            i = i+1\n",
    "        return arr\n",
    "    \n",
    "commasv = read_tsv(nf_filen)\n",
    "print commasv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['March 17, 1963']\n",
      "1963-03-17 00:00:00\n",
      "['May 12, 1963']\n",
      "1963-05-12 00:00:00\n",
      "['March 31, 1963']\n",
      "1963-03-31 00:00:00\n",
      "['May 5, 1963']\n",
      "1963-05-05 00:00:00\n",
      "['May 26, 1963']\n",
      "1963-05-26 00:00:00\n",
      "['March 24, 1963']\n",
      "1963-03-24 00:00:00\n",
      "['April 7, 1963']\n",
      "1963-04-07 00:00:00\n",
      "['April 14, 1963']\n",
      "1963-04-14 00:00:00\n",
      "['April 28, 1963']\n",
      "1963-04-28 00:00:00\n",
      "['May 19, 1963']\n",
      "1963-05-19 00:00:00\n",
      "['April 21, 1963']\n",
      "1963-04-21 00:00:00\n",
      "[[[datetime.datetime(1963, 5, 26, 0, 0), '1', 'THE GLASS BLOWERS, by Daphne du Maurier', '1', '8'], [datetime.datetime(1963, 5, 26, 0, 0), '2', 'SEVEN DAYS IN MAY, by Fletcher Knebel and Charles W. Bailey II.', '2', '35'], [datetime.datetime(1963, 5, 26, 0, 0), '3', 'RAISE HIGH THE ROOF BEAM, CARPENTERS, by J.D. Salinger', '3', '15'], [datetime.datetime(1963, 5, 26, 0, 0), '4', 'GRANDMOTHER AND THE PRIESTS, by Taylor Caldwell.', '4', '8'], [datetime.datetime(1963, 5, 26, 0, 0), '5', 'THE SAND PEBBLES, by Richard McKenna.', '5', '19'], [datetime.datetime(1963, 5, 26, 0, 0), '6', 'THE TIN DRUM, by Gunter Grass.', '7', '5'], [datetime.datetime(1963, 5, 26, 0, 0), '7', 'THE MOONFLOWER VINE, by Jetta Carleton', '6', '14'], [datetime.datetime(1963, 5, 26, 0, 0), '8', 'THE MOONSPINNERS, by Mary Stewart.', '--', '19'], [datetime.datetime(1963, 5, 26, 0, 0), '9', 'FAIL-SAFE, by Eugene Burdick and Harvey Wheeler.', '10', '30'], [datetime.datetime(1963, 5, 26, 0, 0), '10', 'THE BEDFORD INCIDENT, by Mark Rascovich.', '9', '2']], [[datetime.datetime(1963, 3, 24, 0, 0), '1', 'RAISE HIGH THE ROOF BEAM, CARPENTERS, by J.D. Salinger', '1', '6'], [datetime.datetime(1963, 3, 24, 0, 0), '2', 'SEVEN DAYS IN MAY, by Fletcher Knebel and Charles W. Bailey II.', '2', '26'], [datetime.datetime(1963, 3, 24, 0, 0), '3', 'THE SAND PEBBLES, by Richard McKenna.', '3', '10'], [datetime.datetime(1963, 3, 24, 0, 0), '4', 'FAIL-SAFE, by Eugene Burdick and Harvey Wheeler.', '4', '20'], [datetime.datetime(1963, 3, 24, 0, 0), '5', 'THE MOONSPINNERS, by Mary Stewart.', '5', '11'], [datetime.datetime(1963, 3, 24, 0, 0), '6', 'THE MOONFLOWER VINE, by Jetta Carleton', '9', '5'], [datetime.datetime(1963, 3, 24, 0, 0), '7', 'TRIUMPH, by Philip Wylie.', '6', '3'], [datetime.datetime(1963, 3, 24, 0, 0), '8', '$100 MISUNDERSTANDING, by Robert Gover.', '8', '15'], [datetime.datetime(1963, 3, 24, 0, 0), '9', 'THE CENTAUR, by John Updike', '10', '3'], [datetime.datetime(1963, 3, 24, 0, 0), '10', 'A SHADE OF DIFFERENCE, by Allen Drury.', '7', '24']], [[datetime.datetime(1963, 4, 7, 0, 0), '1', 'RAISE HIGH THE ROOF BEAM, CARPENTERS, by J.D. Salinger', '1', '8'], [datetime.datetime(1963, 4, 7, 0, 0), '2', 'SEVEN DAYS IN MAY, by Fletcher Knebel and Charles W. Bailey II.', '2', '28'], [datetime.datetime(1963, 4, 7, 0, 0), '3', 'THE SAND PEBBLES, by Richard McKenna.', '3', '12'], [datetime.datetime(1963, 4, 7, 0, 0), '4', 'FAIL-SAFE, by Eugene Burdick and Harvey Wheeler.', '4', '22'], [datetime.datetime(1963, 4, 7, 0, 0), '5', 'THE MOONSPINNERS, by Mary Stewart.', '6', '13'], [datetime.datetime(1963, 4, 7, 0, 0), '6', 'THE MOONFLOWER VINE, by Jetta Carleton', '5', '7'], [datetime.datetime(1963, 4, 7, 0, 0), '7', 'TRIUMPH, by Philip Wylie.', '7', '5'], [datetime.datetime(1963, 4, 7, 0, 0), '8', '$100 MISUNDERSTANDING, by Robert Gover.', '--', '16'], [datetime.datetime(1963, 4, 7, 0, 0), '9', 'THE CENTAUR, by John Updike', '10', '5'], [datetime.datetime(1963, 4, 7, 0, 0), '10', 'A SHADE OF DIFFERENCE, by Allen Drury.', '--', '25']], [[datetime.datetime(1963, 4, 14, 0, 0), '1', 'RAISE HIGH THE ROOF BEAM, CARPENTERS, by J.D. Salinger', '1', '9'], [datetime.datetime(1963, 4, 14, 0, 0), '2', 'SEVEN DAYS IN MAY, by Fletcher Knebel and Charles W. Bailey II.', '2', '29'], [datetime.datetime(1963, 4, 14, 0, 0), '3', 'THE SAND PEBBLES, by Richard McKenna.', '3', '13'], [datetime.datetime(1963, 4, 14, 0, 0), '4', 'THE GLASS BLOWERS, by Daphne du Maurier', '--', '2'], [datetime.datetime(1963, 4, 14, 0, 0), '5', 'FAIL-SAFE, by Eugene Burdick and Harvey Wheeler.', '4', '24'], [datetime.datetime(1963, 4, 14, 0, 0), '6', 'THE MOONFLOWER VINE, by Jetta Carleton', '6', '8'], [datetime.datetime(1963, 4, 14, 0, 0), '7', 'THE MOONSPINNERS, by Mary Stewart.', '5', '14'], [datetime.datetime(1963, 4, 14, 0, 0), '8', 'TRIUMPH, by Philip Wylie.', '7', '6'], [datetime.datetime(1963, 4, 14, 0, 0), '9', 'GRANDMOTHER AND THE PRIESTS, by Taylor Caldwell.', '--', '2'], [datetime.datetime(1963, 4, 14, 0, 0), '10', 'THE TIN DRUM, by Gunter Grass.', '--', '1']]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"1963/fiction/\"\n",
    "sixtythree = []\n",
    "for f in os.listdir(path):\n",
    "    commasv = read_tsv(path+f)\n",
    "    sixtythree.append(commasv)\n",
    "    \n",
    "print sixtythree[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('THE GLASS BLOWERS', set(['Daphne du Maurier']))\n"
     ]
    }
   ],
   "source": [
    "sample_title_auth = commasv[2][2]\n",
    "#print sample_title_auth\n",
    "\n",
    "#index into phrase to skip \" by\"\n",
    "auth_i = 4\n",
    "\n",
    "def title_author_pair(data_str):\n",
    "    split_str = data_str.split(',')\n",
    "    title = \"\"\n",
    "    authors = set()\n",
    "    i=0\n",
    "    for phrase in split_str:\n",
    "        if i == 0:\n",
    "            title = phrase\n",
    "        else:\n",
    "            if phrase.isupper():\n",
    "                title = title + \", \"+phrase\n",
    "            else:\n",
    "                author_ph = phrase[auth_i:]\n",
    "                if \" and \" in author_ph:\n",
    "                    author_arr = author_ph.split(\" and \")\n",
    "                    for author in author_arr:\n",
    "                        if author[len(author)-1]=='.':\n",
    "                            author = author[:len(author)-1] # strip trailing period\n",
    "                        authors.add(author)\n",
    "                else:\n",
    "                    author = author_ph\n",
    "                    if author[len(author)-1]=='.':\n",
    "                        author = author[:len(author)-1] # strip trailing period\n",
    "                    authors.add(author)\n",
    "        i = i+1\n",
    "    return (title,authors)\n",
    "        \n",
    "print title_author_pair(sample_title_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RAISE HIGH THE ROOF BEAM,  CARPENTERS', set(['J.D. Salinger']))\n",
      "('SEVEN DAYS IN MAY', set(['Fletcher Knebel', 'Charles W. Bailey II']))\n",
      "('THE GLASS BLOWERS', set(['Daphne du Maurier']))\n",
      "('THE SAND PEBBLES', set(['Richard McKenna']))\n",
      "('THE MOONFLOWER VINE', set(['Jetta Carleton']))\n",
      "('THE MOONSPINNERS', set(['Mary Stewart']))\n",
      "('GRANDMOTHER AND THE PRIESTS', set(['Taylor Caldwell']))\n",
      "('FAIL-SAFE', set(['Eugene Burdick', 'Harvey Wheeler']))\n",
      "('TRIUMPH', set(['Philip Wylie']))\n",
      "('THE CENTAUR', set(['John Updike']))\n"
     ]
    }
   ],
   "source": [
    "for row in commasv:\n",
    "    print(title_author_pair(row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Storage\n",
    "\n",
    "Store all data as we go through as a table (or look into pandas dataframe?). Each row is a BestSellers row and is formatted:\n",
    "\n",
    "* date -- date\n",
    "* title -- string\n",
    "* author(s) -- arr[string]\n",
    "* isbn_list -- arr[int]\n",
    "* author_wiki_dat_id -- int\n",
    "* author_gender(s) -- arr[string]\n",
    "\n",
    "Maybe if there are too few ISBN matches for a book I should flag it for manual tagging? How few is too few? Will have to experiment.\n",
    "\n",
    "Also want to store running dictionaries of these values so I don't need to call the function for the repeat appearances:\n",
    "\n",
    "* {(Title,Author):[isbn_list, gender]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ISBN from Title/Author Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manual_titles = set()\n",
    "manual_genders = set()\n",
    "done_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api-2445581351187.apicast.io:443/search?app_key=62f7cedf62afa7006026634aaadce211&app_id=7f7512d5&t=Potatoes\n",
      "http://isbndb.com/api/books.xml?access_key=1DR9S9TA&index1=title&value1=Potatoes\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree\n",
    "import urllib2\n",
    "import re, string\n",
    "%run \"key.py\"\n",
    "\n",
    "suffixes = ['CPA', 'CSC', 'CSJ', 'DC', 'DD', 'DDS', 'DMD', 'DO', 'DVM', 'EDD', 'ESQ', 'II', 'III', \n",
    "            'IV', 'INC', 'JD', 'JR', 'LLD', 'LTD', 'MD', 'OD', 'OSB', 'PC', 'PE', 'PHD', 'RET', \n",
    "            'RGS', 'RN', 'RNC', 'SHCJ', 'SJ', 'SNJM', 'SR', 'SSMO', 'USA', 'USAF', 'USAFR', 'USAR', \n",
    "            'USCG', 'USMC', 'USMCR', 'USN', 'USNR']\n",
    "\n",
    "digits = ['1','2','3','4','5','6','7','8','9','0']\n",
    "symbol_dict = {'%':'percent','$':'dollar', '1/2':'half'}\n",
    "\n",
    "isbn_plus_base_url = \"https://api-2445581351187.apicast.io:443\"\n",
    "plus_key = isbn_plus_key\n",
    "app_id = \"7f7512d5\"\n",
    "search_plus = \"/search?app_key=\"+plus_key+\"&app_id=\"+app_id+\"&t=\"\n",
    "print isbn_plus_base_url+search_plus+\"Potatoes\"\n",
    "alph = re.compile('[^a-zA-Z]')\n",
    "\n",
    "db_key = isbn_db_key\n",
    "isbn_db_base = \"http://isbndb.com/api\"\n",
    "search_db = \"/books.xml?access_key=\"+db_key+\"&index1=title&value1=\"\n",
    "print isbn_db_base+search_db+\"Potatoes\"\n",
    "\n",
    "def convert_to_search(name):\n",
    "    return_string = \"\"\n",
    "    last_ch = \" \"\n",
    "    for ch in name:\n",
    "        if (ch == \" \"):\n",
    "            if (last_ch != \".\"):\n",
    "                return_string = return_string + \"+\"\n",
    "        else:\n",
    "            if ch == \".\":\n",
    "                return_string = return_string +\".+\"\n",
    "            else:\n",
    "                return_string = return_string+ch\n",
    "        last_ch = ch\n",
    "    return return_string\n",
    "\n",
    "def url_to_xml(url):\n",
    "    req = urllib2.Request(url)\n",
    "    req.add_header('User-agent', 'Mozilla 5.10')\n",
    "    res = urllib2.urlopen(req)\n",
    "    print res\n",
    "    data = xml.etree.ElementTree.parse(res).getroot()[0]\n",
    "    for book in data.findall('BookData'):\n",
    "        isbn = book.get('isbn')\n",
    "        title = book.find('Title').text\n",
    "        author = book.find('AuthorsText').text\n",
    "        print(isbn,title,author)\n",
    "    return data\n",
    "\n",
    "def suffix(phrase):\n",
    "    norm_phrase = phrase.replace(',',\"\").upper()\n",
    "    if norm_phrase in suffixes:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def last_name_recursive(name,last_index):\n",
    "    if last_index == 0:\n",
    "        return \"\"\n",
    "    last_phrase = name[last_index]\n",
    "    if not suffix(last_phrase):\n",
    "        return last_phrase\n",
    "    else:\n",
    "        return last_name_recursive(name, last_index-1)\n",
    "\n",
    "def last_name(name):\n",
    "    names = name.split(\" \")\n",
    "    last_index = len(names)-1\n",
    "    last = last_name_recursive(names,last_index)\n",
    "    return last\n",
    "\n",
    "def strip_punct(text):\n",
    "    return alph.sub('', text)\n",
    "\n",
    "def has_numbers(text):\n",
    "    for digit in digits:\n",
    "        if digit in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_symbols(text):\n",
    "    for symbol in symbol_dict:\n",
    "        if symbol in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def norm_text(text):\n",
    "    return strip_punct(text).lower()\n",
    "\n",
    "def is_book(booxml, title, authors, year):\n",
    "    xml_title = booxml.find('Title').text\n",
    "    norm_xml_title = norm_text(xml_title)\n",
    "    norm_title = norm_text(title)\n",
    "    if(norm_xml_title in norm_title) or (norm_title in norm_xml_title):\n",
    "        xml_authors = booxml.find('AuthorsText').text\n",
    "        if xml_authors is None:\n",
    "            return False\n",
    "        for author in authors:\n",
    "            if norm_text(author) in norm_text(xml_authors):\n",
    "                print \"Adding ISBN! \"+xml_title+\" by \"+xml_authors\n",
    "                return True\n",
    "            xml_names = []\n",
    "            for xmla in xml_authors.split(\" \"):\n",
    "                norm_text(xmla)\n",
    "            for author in authors:\n",
    "                if norm_text(last_name(author)) in xml_authors.split(\" \"):\n",
    "                    print \"Adding ISBN! \"+xml_title+\" by \"+xml_authors\n",
    "                    return True        \n",
    "        return False\n",
    "\n",
    "def get_isbns(title,authors,year):\n",
    "    isbns = set()\n",
    "    search_t = convert_to_search(title)\n",
    "    url = isbn_db_base+search_db+search_t\n",
    "#    print row[0].year\n",
    "    data = url_to_xml(url)\n",
    "    for book in data:\n",
    "        if (is_book(book,title,authors,year)):\n",
    "            isbns.add(book.get('isbn'))\n",
    "    return isbns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RAISE HIGH THE ROOF BEAM,  CARPENTERS', set(['J.D. Salinger']))\n",
      "<addinfourl at 140356786125712 whose fp = <socket._fileobject object at 0x7fa75c6aaa50>>\n",
      "('0241950465', 'Raise High the Roof Beam, Carpenters', None)\n",
      "('0553142828', 'Raise high the roof beam, carpenters', None)\n",
      "('0140237518', 'Raise High the Roof Beam, Carpenters', 'J. D. Salinger, ')\n",
      "('0141049243', 'Raise High the Roof Beam, Carpenters. Seymour', 'J.D. Salinger, ')\n",
      "('055320596X', 'Raise high the roof beam, carpenters; and, Seymour', 'J. D. Salinger')\n",
      "('0316769517', 'Raise High the Roof Beam, Carpenters and Seymour', 'J. D. Salinger, ')\n",
      "('0140022643', 'Raise high the roof beam, carpenters; and Seymour', 'J. D. Salinger')\n",
      "('0316766941', 'Raise high the roof beam, carpenters', None)\n",
      "('0316769576', 'Raise high the roof beam, carpenters', None)\n",
      "('0553125540', 'Raise high the roof beam, carpenters', 'J. D. Salinger')\n",
      "Adding ISBN! Raise High the Roof Beam, Carpenters by J. D. Salinger, \n",
      "Adding ISBN! Raise High the Roof Beam, Carpenters. Seymour by J.D. Salinger, \n",
      "Adding ISBN! Raise high the roof beam, carpenters; and, Seymour by J. D. Salinger\n",
      "Adding ISBN! Raise High the Roof Beam, Carpenters and Seymour by J. D. Salinger, \n",
      "Adding ISBN! Raise high the roof beam, carpenters; and Seymour by J. D. Salinger\n",
      "Adding ISBN! Raise high the roof beam, carpenters by J. D. Salinger\n",
      "set(['0553125540', '0316769517', '055320596X', '0141049243', '0140237518', '0140022643'])\n",
      "('SEVEN DAYS IN MAY', set(['Fletcher Knebel', 'Charles W. Bailey II']))\n",
      "<addinfourl at 140356920769136 whose fp = <socket._fileobject object at 0x7fa75c362f50>>\n",
      "('0553269569', 'SEVEN DAYS IN MAY', 'FLETCHER KNEBEL')\n",
      "('0854565558', 'Seven Days in May', 'Fletcher Knebel, ')\n",
      "('0553131699', 'Seven Days in May', 'Fletcher Knebel, ')\n",
      "('0060124369', 'Seven Days in May', 'F. Knebel, ')\n",
      "('1580812430', 'Seven Days In May', 'Kristin Sergel, ')\n",
      "('0060124350', 'Seven Days In May: A Novel', 'Fletcher Knebel, Charles W Bailey II, ')\n",
      "('0972908609', 'Seven Days in Missouri', None)\n",
      "('0609609793', 'Seven days & seven sins', 'Pamela Ditchoff')\n",
      "('1780882475', 'Stop bedwetting in seven days', 'Alicia Eaton.')\n",
      "('9780953917', 'Seven days in July', 'A.M. Coombs.')\n",
      "Adding ISBN! SEVEN DAYS IN MAY by FLETCHER KNEBEL\n",
      "Adding ISBN! Seven Days in May by Fletcher Knebel, \n",
      "Adding ISBN! Seven Days in May by Fletcher Knebel, \n",
      "Adding ISBN! Seven Days In May: A Novel by Fletcher Knebel, Charles W Bailey II, \n",
      "set(['0553131699', '0854565558', '0060124350', '0553269569'])\n",
      "('THE GLASS BLOWERS', set(['Daphne du Maurier']))\n",
      "<addinfourl at 140356785952024 whose fp = <socket._fileobject object at 0x7fa75c365650>>\n",
      "('0140236740', \"The glass blower's breath\", 'Sunetra Gupta')\n",
      "('1568495617', 'The Glass Blowers', 'Daphne, Dame Du Maurier, ')\n",
      "('0862251486', 'The Glass-Blowers', 'Daphne Du Maurier, ')\n",
      "('0708981763', 'The Glass Blowers', 'Dame Daphne Du Maurier, ')\n",
      "('0575010800', 'The glass-blowers', 'by Daphne du Maurier')\n",
      "('0140024034', 'The glass-blowers', 'Daphne du Maurier')\n",
      "('0575029226', 'The glass-blowers', 'by Daphne du Maurier')\n",
      "('0590551825', 'Rosie & Jim and the glass blowers', 'written by John Cunliffe ; illustrated by Celia Berridge')\n",
      "('184408065X', 'The Glass-Blowers', 'Daphne Du Maurier, Michelle De Kretser (Introduction)')\n",
      "('081613491X', 'The glass-blowers', 'Daphne du Maurier')\n",
      "Adding ISBN! The Glass-Blowers by Daphne Du Maurier, \n",
      "Adding ISBN! The Glass Blowers by Dame Daphne Du Maurier, \n",
      "Adding ISBN! The glass-blowers by by Daphne du Maurier\n",
      "Adding ISBN! The glass-blowers by Daphne du Maurier\n",
      "Adding ISBN! The glass-blowers by by Daphne du Maurier\n",
      "Adding ISBN! The Glass-Blowers by Daphne Du Maurier, Michelle De Kretser (Introduction)\n",
      "Adding ISBN! The glass-blowers by Daphne du Maurier\n",
      "set(['0575010800', '0140024034', '0575029226', '081613491X', '0862251486', '0708981763', '184408065X'])\n",
      "('THE SAND PEBBLES', set(['Richard McKenna']))\n",
      "<addinfourl at 140356786143528 whose fp = <socket._fileobject object at 0x7fa75c365750>>\n",
      "('0948699310', 'Pebbles on the sand', 'Betty Blunt.')\n",
      "('0795305125', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0231109261', 'Realms of memory', 'under the direction of Pierre Nora; English language edition edited and with a foreword by Lawrence D. Kritzman; translated by Arthur Goldhammer')\n",
      "('1599534096', \"Pebbles, Sand, & Silt: The Neighbor's Garden\", 'Emily Sohn and Diane Bair, ')\n",
      "('0887060609', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0887060595', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "('0899668577', 'The Sand Pebbles', 'Richard McKenna, ')\n",
      "('0870215922', 'The sand pebbles', 'by Richard McKenna; with an introduction by Robert Shenk')\n",
      "('158909817X', 'Pebbles', 'Davis K. Thanjan, ')\n",
      "('0585061408', 'Sand and pebbles (Shasekish?)', '[translated and edited by] Robert E. Morrell')\n",
      "Adding ISBN! The Sand Pebbles by Richard McKenna, \n",
      "Adding ISBN! The Sand Pebbles by Richard McKenna, \n",
      "Adding ISBN! The sand pebbles by by Richard McKenna; with an introduction by Robert Shenk\n",
      "set(['0870215922', '0899668577', '0795305125'])\n",
      "('THE MOONFLOWER VINE', set(['Jetta Carleton']))\n",
      "<addinfourl at 140356783467192 whose fp = <socket._fileobject object at 0x7fa75c365550>>\n",
      "('0061673234', 'The moonflower vine', 'Jetta Carleton; foreword by Jane Smiley')\n",
      "('156145138X', 'The Moonflower', 'Jean Loewer, Peter Loewer (Illustrator)')\n",
      "('0263105288', 'The moonflower', 'Valentine Luellen')\n",
      "('1567183859', 'Moonflower', 'Sirona Knight, ')\n",
      "('0491011113', 'The moonflower', None)\n",
      "('1561453145', 'The Moonflower', 'Peter Loewer, H. Peter Loewer, Jean Loewer (Illustrator)')\n",
      "('140523847X', 'The Mystical Moonflower', None)\n",
      "('0373821247', 'Night of the Moonflower', 'Anne Vinton, ')\n",
      "('0333131401', 'The frog in the moonflower', None)\n",
      "('0515033529', 'The Frog in the Moonflower', 'Ivor Drummond, ')\n",
      "Adding ISBN! The moonflower vine by Jetta Carleton; foreword by Jane Smiley\n",
      "set(['0061673234'])\n",
      "('THE MOONSPINNERS', set(['Mary Stewart']))\n",
      "<addinfourl at 140356783086696 whose fp = <socket._fileobject object at 0x7fa75c365a50>>\n",
      "('0194216640', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0722331487', 'Moonspinner the grey', 'Mary Tuckett.')\n",
      "('3464127788', 'The Moonspinners.', 'Mary Stewart, Diane. Mowat, Bob Harvey, ')\n",
      "('0194230392', 'The Oxford Bookworms Library: Stage 4: 1,400 Headwords: The Moonspinners: 1400 Headwords', 'Mary Stewart, Diane Mowat, Tricia Hedge (Contributor), Jennifer Basset (Contributor)')\n",
      "('0905712412', 'The moonspinners; Nine coaches waiting; The ivy tree; Madam, will you talk?', 'Mary Stewart')\n",
      "('067717604X', 'The Moon-Spinners: A Spellbinding Suspense Thriller', 'Mary Stewart, Crest Books (Editor), A.E. Gunther (Editor), M.S. Mill (Editor), Walt Disney (Illustrator)')\n",
      "('0340013613', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0194791785', 'The Moonspinners', None)\n",
      "('0706610520', 'The Moonspinners', 'Mary Stewart, ')\n",
      "('0060502959', 'The Moonspinners', 'Mary Stewart, ')\n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "Adding ISBN! The Moonspinners. by Mary Stewart, Diane. Mowat, Bob Harvey, \n",
      "Adding ISBN! The Oxford Bookworms Library: Stage 4: 1,400 Headwords: The Moonspinners: 1400 Headwords by Mary Stewart, Diane Mowat, Tricia Hedge (Contributor), Jennifer Basset (Contributor)\n",
      "Adding ISBN! The moonspinners; Nine coaches waiting; The ivy tree; Madam, will you talk? by Mary Stewart\n",
      "Adding ISBN! The Moon-Spinners: A Spellbinding Suspense Thriller by Mary Stewart, Crest Books (Editor), A.E. Gunther (Editor), M.S. Mill (Editor), Walt Disney (Illustrator)\n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "Adding ISBN! The Moonspinners by Mary Stewart, \n",
      "set(['0706610520', '3464127788', '0905712412', '067717604X', '0194216640', '0060502959', '0340013613', '0194230392'])\n",
      "('GRANDMOTHER AND THE PRIESTS', set(['Taylor Caldwell']))\n",
      "<addinfourl at 140356783084176 whose fp = <socket._fileobject object at 0x7fa75c365950>>\n",
      "('0449213870', 'Grandmother and the Priests', 'Taylor Caldwell, ')\n",
      "('0449240274', 'Grandmother and the priests', 'Taylor Caldwell')\n",
      "('0665056354', 'His grandmothers', None)\n",
      "('0749397314', \"The Grandmother's Tale\", 'R K Narayan, ')\n",
      "('051707009X', \"The Grandmother's Book\", 'Marcia O. Levin, ')\n",
      "('1550373374', 'The Grandmother Doll', None)\n",
      "('0823304442', \"Grandmother's quilt\", 'Esther Buffler')\n",
      "('0882291289', 'The single grandmother', None)\n",
      "('0879052538', \"The grandmothers' club\", 'Alan Cheuse')\n",
      "('0416660606', 'The grandmother stone', 'Margaret Greaves')\n",
      "Adding ISBN! Grandmother and the Priests by Taylor Caldwell, \n",
      "Adding ISBN! Grandmother and the priests by Taylor Caldwell\n",
      "set(['0449213870', '0449240274'])\n",
      "('FAIL-SAFE', set(['Eugene Burdick', 'Harvey Wheeler']))\n",
      "<addinfourl at 140356783085616 whose fp = <socket._fileobject object at 0x7fa75c36a4d0>>\n",
      "('0749223707', 'Fail Safe', 'A. Demaid, ')\n",
      "('088001654X', 'Fail-safe', 'Eugene Burdick & Harvey Wheeler')\n",
      "('0971573212', 'Fail - Safe Leadership', 'Linda Martin, Dr. David G. Mutchler, ')\n",
      "('0399126163', 'Fail-safe investing', 'Peter Nagan')\n",
      "('0132995867', 'Fail-safe business negotiating', 'Philip Sperber')\n",
      "('0132995786', 'Fail-safe business negotiating', 'Philip Sperber')\n",
      "('0312247036', 'Fail-safe investing', 'Harry Browne')\n",
      "('046502274X', 'The fail-safe society', 'Charles Piller')\n",
      "('0471014389', 'Fail-safe small businesses', 'Ron Tepper')\n",
      "('0471014370', 'Fail-safe small businesses', 'Ron Tepper')\n",
      "Adding ISBN! Fail-safe by Eugene Burdick & Harvey Wheeler\n",
      "set(['088001654X'])\n",
      "('TRIUMPH', set(['Philip Wylie']))\n",
      "<addinfourl at 140356783466760 whose fp = <socket._fileobject object at 0x7fa75c365a50>>\n",
      "('1740211901', \"Dolphin's Triumph\", None)\n",
      "('0670918717', 'Triumph', None)\n",
      "('1841497622', \"Orphan's Triumph\", None)\n",
      "('042507644X', 'Triumph', 'Oliver Payne, ')\n",
      "('1855321246', 'Triumph', 'Don Morley, ')\n",
      "('1594270260', 'Conditional triumphs', 'Bernard Saper.')\n",
      "('0263143007', 'Tangled triumphs', None)\n",
      "('0373085095', 'Tangled triumphs', 'Terri Herrington.')\n",
      "('0340411988', 'The triumph', 'Ernest K. Gann')\n",
      "('0851462324', 'Triumph acclaim', 'Autobooks.')\n",
      "('THE CENTAUR', set(['John Updike']))\n",
      "<addinfourl at 140356783136136 whose fp = <socket._fileobject object at 0x7fa75c36a450>>\n",
      "('023396360X', 'The centaur', None)\n",
      "('0233983058', 'The centaur', 'John Updike')\n",
      "('0394418816', 'The centaur', 'John Updike')\n",
      "('1557530769', 'The Centaur Types', 'Bruce Rogers, ')\n",
      "('1562791311', \"The centaur's son\", 'Philip Daughtry')\n",
      "('0955193249', 'The ant and the centaur', 'Stephen Brown.')\n",
      "('8472233820', 'El Centauro / The Centaur', 'John Updike, ')\n",
      "('0393038475', 'Dreams of the centaur', 'Montserrat Fontes')\n",
      "('0969280122', \"The Centaur's mountain\", 'Philip Resnick, Ron Walkey')\n",
      "('0916620069', 'The Mexican centaur', 'Oren Arnold')\n",
      "Adding ISBN! The centaur by John Updike\n",
      "Adding ISBN! The centaur by John Updike\n",
      "Adding ISBN! El Centauro / The Centaur by John Updike, \n",
      "set(['0394418816', '0233983058', '8472233820'])\n",
      "[('TRIUMPH', set(['Philip Wylie']))]\n"
     ]
    }
   ],
   "source": [
    "for row in commasv:\n",
    "    title_author = title_author_pair(row[2])\n",
    "    print title_author\n",
    "    if has_symbols(title_author[0]) or has_numbers(title_author[0]):\n",
    "        manual_titles.add(title_author)\n",
    "    else:\n",
    "        isbns = get_isbns(title_author[0],title_author[1],1963)\n",
    "        if len(isbns) == 0:\n",
    "            manual_titles.add(title_author)\n",
    "        else:\n",
    "            print isbns\n",
    "\n",
    "\n",
    "print manual_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Gender Data from Author Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_name_to_id = \"https://www.wikidata.org/w/api.php?action=wbsearchentities&language=en&format=json&search=\"\n",
    "wiki_id_to_data = \"https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=\"\n",
    "gender_prop_id = \"P21\"\n",
    "wiki_gender_hash = {\"Q6581097\":\"male\", \"Q6581072\":\"female\",\"Q1052281\":\"transf\",\"Q2449503\":\"transm\",\"Q1097630\":\"intersex\"}\n",
    "\n",
    "import urllib2\n",
    "import json\n",
    "\n",
    "def url_to_data( url ):\n",
    "    req = urllib2.Request(url)\n",
    "    req.add_header('User-agent', 'Mozilla 5.10')\n",
    "    res = urllib2.urlopen(req)\n",
    "    data = json.load(res)\n",
    "    return data\n",
    "\n",
    "def same_gender(id_list):\n",
    "    id_0 = id_list[0]\n",
    "    for i in id_list[1:]:\n",
    "        if gender_from_id(id_0) != gender_from_id(i):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "## This needs to disambiguate -- does it need to pull more information by id?\n",
    "## Let's do it\n",
    "def disambiguate(entity_data, name):\n",
    "    entities = []\n",
    "    for entity in entity_data:\n",
    "        if 'description' in entity:\n",
    "            desc = entity['description'].lower()\n",
    "            ent_id = entity['id']\n",
    "            if ('novel' in desc) or ('write' in desc) or ('auth' in desc) or ('cartoo' in desc) or ('journ' in desc) or ('comic' in desc):\n",
    "                entities.append((ent_id,desc))\n",
    "    if len(entities)==0:\n",
    "        print \"No novelists, writers, authors, cartoonists, journalists or comics named \"+name\n",
    "        manual_genders.add(name)\n",
    "        for x in entity_data:\n",
    "            print x\n",
    "    return entities\n",
    "\n",
    "def get_wiki_id(name):\n",
    "    search_term = convert_to_search(name)\n",
    "    url = wiki_name_to_id + search_term\n",
    "    data = url_to_data(url)['search']\n",
    "    if data == []:\n",
    "        return [-1]\n",
    "    dis_data = disambiguate(data,name)\n",
    "    if dis_data == []:\n",
    "        return [-1]\n",
    "    i = []\n",
    "    for entity in dis_data:\n",
    "        i.append(entity[0])\n",
    "    return i\n",
    "\n",
    "def gender_from_id(auth_id):\n",
    "    url = wiki_id_to_data + auth_id\n",
    "    print url\n",
    "    claims = url_to_data(url)['entities'][str(auth_id)]['claims']['P21']\n",
    "    gender_arr =[]\n",
    "    for claim in claims:\n",
    "        if claim['mainsnak']['datavalue']['value'] is not None:\n",
    "            gender_id = claim['mainsnak']['datavalue']['value']['id']\n",
    "            gender_arr.append(wiki_gender_hash[gender_id])\n",
    "    if len(gender_arr)>1:\n",
    "        gender = max_value(gender_arr) ## FIX THIS\n",
    "    else:\n",
    "        gender = gender_arr[0]\n",
    "    return gender\n",
    "\n",
    "\n",
    "#def book_to_key_facts(book_data):\n",
    "\n",
    "def author_to_gender(author_name):\n",
    "    gender = \"\"\n",
    "    author_id = []\n",
    "    author_id = get_wiki_id(author_name)\n",
    "    print author_id\n",
    "    if author_id[0] == -1:\n",
    "        print \"Unable to find \"+author_name+\" in database\"\n",
    "        return \"unknown\"\n",
    "    if len(author_id)>1:\n",
    "        print \"More than one writer by the name \"+author_name\n",
    "        if(same_gender(author_id)):\n",
    "            gender = gender_from_id(author_id[0])\n",
    "    else:\n",
    "        gender = gender_from_id(author_id[0])\n",
    "        return gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FUCK WIKIDATA, LIBRARIES GOT ME COVERED\n",
    "\n",
    "Look up book genres by ISBN using this tool:\n",
    "\n",
    "https://platform.worldcat.org/api-explorer/apis/Classify\n",
    "\n",
    "classify.oclc.org/classify2/Classify?oclc=57358293&summary=true\n",
    "\n",
    "I could also apparently use this to GET isbns -- I'll try it for a table and compare.\n",
    "\n",
    "This returns authors per book with their names and VIAF id, which I can look up here:\n",
    "\n",
    "https://platform.worldcat.org/api-explorer/apis/VIAF\n",
    "https://platform.worldcat.org/api-explorer/apis/VIAF/AuthorityCluster/Identify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Q15637611']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q15637611\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "print author_to_gender(\"Virginia Cary Hudson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Q39212', u'Q5559244']\n",
      "More than one writer by the name John Steinbeck\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q39212\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q5559244\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q39212\n",
      "John Steinbeck was a male\n",
      "[u'Q298920']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q298920\n",
      "Charles M. Schulz was a male\n",
      "[u'Q353774']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q353774\n",
      "Adela Rogers St. Johns was a female\n",
      "No novelists, writers, authors, cartoonists, journalists or comics named Hedda Hopper\n",
      "{u'pageid': 262584, u'description': u'Actress, gossip columnist, radio personality', u'title': u'Q271324', u'concepturi': u'http://www.wikidata.org/entity/Q271324', u'label': u'Hedda Hopper', u'url': u'//www.wikidata.org/wiki/Q271324', u'id': u'Q271324', u'match': {u'text': u'Hedda Hopper', u'type': u'label', u'language': u'en'}}\n",
      "[-1]\n",
      "Unable to find Hedda Hopper in database\n",
      "Hedda Hopper was a unknown\n",
      "[u'Q15637611']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q15637611\n",
      "Virginia Cary Hudson was a female\n",
      "[u'Q273210', u'Q15976232', u'Q18529778']\n",
      "More than one writer by the name James Baldwin\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q273210\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q15976232\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q273210\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q18529778\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q273210\n",
      "James Baldwin was a male\n",
      "No novelists, writers, authors, cartoonists, journalists or comics named Rachel Carson\n",
      "{u'pageid': 103533, u'description': u'American marine biologist and conservationist', u'title': u'Q100948', u'concepturi': u'http://www.wikidata.org/entity/Q100948', u'label': u'Rachel Carson', u'url': u'//www.wikidata.org/wiki/Q100948', u'id': u'Q100948', u'match': {u'text': u'Rachel Carson', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 29871282, u'title': u'Q28173403', u'concepturi': u'http://www.wikidata.org/entity/Q28173403', u'label': u'Rachel Carson', u'url': u'//www.wikidata.org/wiki/Q28173403', u'id': u'Q28173403', u'match': {u'text': u'Rachel Carson', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 7183370, u'description': u'Wikipedia disambiguation page', u'title': u'Q7279182', u'concepturi': u'http://www.wikidata.org/entity/Q7279182', u'label': u'Rachel Carson', u'url': u'//www.wikidata.org/wiki/Q7279182', u'id': u'Q7279182', u'match': {u'text': u'Rachel Carson', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 737099, u'description': u'award', u'title': u'Q784097', u'concepturi': u'http://www.wikidata.org/entity/Q784097', u'label': u'Rachel Carson Prize', u'url': u'//www.wikidata.org/wiki/Q784097', u'id': u'Q784097', u'match': {u'text': u'Rachel Carson Prize', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 2051353, u'description': u'Wikipedia disambiguation page', u'title': u'Q2125206', u'concepturi': u'http://www.wikidata.org/entity/Q2125206', u'label': u'Rachel Carson House', u'url': u'//www.wikidata.org/wiki/Q2125206', u'id': u'Q2125206', u'match': {u'text': u'Rachel Carson House', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 2051355, u'title': u'Q2125208', u'concepturi': u'http://www.wikidata.org/entity/Q2125208', u'label': u'Rachel Carson National Wildlife Refuge', u'url': u'//www.wikidata.org/wiki/Q2125208', u'id': u'Q2125208', u'match': {u'text': u'Rachel Carson National Wildlife Refuge', u'type': u'label', u'language': u'en'}}\n",
      "{u'pageid': 18571902, u'title': u'Q16968120', u'concepturi': u'http://www.wikidata.org/entity/Q16968120', u'label': u'Rachel Carson Award', u'url': u'//www.wikidata.org/wiki/Q16968120', u'id': u'Q16968120', u'match': {u'text': u'Rachel Carson Award', u'type': u'label', u'language': u'en'}}\n",
      "[-1]\n",
      "Unable to find Rachel Carson in database\n",
      "Rachel Carson was a unknown\n",
      "No novelists, writers, authors, cartoonists, journalists or comics named Louis Nizer\n",
      "{u'pageid': 6522048, u'description': u'American lawyer', u'title': u'Q6687903', u'concepturi': u'http://www.wikidata.org/entity/Q6687903', u'label': u'Louis Nizer', u'url': u'//www.wikidata.org/wiki/Q6687903', u'id': u'Q6687903', u'match': {u'text': u'Louis Nizer', u'type': u'label', u'language': u'en'}}\n",
      "[-1]\n",
      "Unable to find Louis Nizer in database\n",
      "Louis Nizer was a unknown\n",
      "[u'Q361617']\n",
      "https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&props=claims&languages=en&ids=Q361617\n",
      "E.B. White was a male\n",
      "[-1]\n",
      "Unable to find Edmond Taylor in database\n",
      "Edmond Taylor was a unknown\n"
     ]
    }
   ],
   "source": [
    "for row in commasv:\n",
    "    authors = title_author_pair(row[2])[1]\n",
    "    for author in authors:\n",
    "        gender = author_to_gender(author)\n",
    "        print author + \" was a \"+gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ISBNS & Author Name to Gender\n",
    "\n",
    "Use the VIAF api https://platform.worldcat.org/api-explorer/apis/VIAF/AuthorityCluster/GetDataInFormat\n",
    "\n",
    "# ISBNS to Subjects/Genres/DDC Category\n",
    "\n",
    "Use the OCLC classify api -- much better than goodreads! http://classify.oclc.org/classify2/api_docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.viaf.org/viaf/102403515/\n",
      "Male\n",
      "Male\n"
     ]
    }
   ],
   "source": [
    "VIAF = {\"Jane Austen\":\"102333412\",\"James Tiptree\":\"266704950\",\"Dan Brown\":\"102403515\",\"J.K. Rowling\":\"116796842\",\n",
    "        \"J.D. Salinger\":\"17092\",\"Chimamanda\":\"87194517\",\"Dostoyevski\":\"104023256\", \"Hedda Hopper\":\"52211425\"}\n",
    "headers= {\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.82 Safari/537.36\"}\n",
    "\n",
    "import urllib2\n",
    "import xml.etree.ElementTree\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "viaf_base = \"http://www.viaf.org/viaf/\"\n",
    "\n",
    "\n",
    "def get_gender(i):\n",
    "    url = viaf_base+str(i)+\"/\"\n",
    "    print url\n",
    "    data = requests.get(url).text\n",
    "    soup = BeautifulSoup(data,\"lxml\")\n",
    "    personal = soup.find('div',{'id':'personalinfo'})\n",
    "    h4s = personal.find('h4')\n",
    "    if len(h4s)<5:\n",
    "        return -1\n",
    "    #print type(h4s)\n",
    "    mt = []\n",
    "    i=0\n",
    "    for h in h4s:\n",
    "        mt.append(h)\n",
    "        #print \"element \"+str(i)+\": \"+str(h)\n",
    "        i = i+1\n",
    "    print mt[4]\n",
    "    return mt[4]\n",
    "\n",
    "print get_gender(VIAF[\"Dan Brown\"])\n",
    "\n",
    "#tree = html.fromstring(page.content)\n",
    "#print page.text\n",
    "#tags =  tree.xpath(\"//*[@id='personalinfo']/h4/span[class='langHi0']\")\n",
    "#print tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102403515\n",
      "http://www.viaf.org/viaf/102403515/\n",
      "Male\n",
      "Dan Brown is tagged as: Male\n",
      "116796842\n",
      "http://www.viaf.org/viaf/116796842/\n",
      "Female\n",
      "J.K. Rowling is tagged as: Female\n",
      "266704950\n",
      "http://www.viaf.org/viaf/266704950/\n",
      "Female\n",
      "James Tiptree is tagged as: Female\n",
      "104023256\n",
      "http://www.viaf.org/viaf/104023256/\n",
      "Male\n",
      "Dostoyevski is tagged as: Male\n",
      "52211425\n",
      "http://www.viaf.org/viaf/52211425/\n",
      "Female\n",
      "Hedda Hopper is tagged as: Female\n",
      "102333412\n",
      "http://www.viaf.org/viaf/102333412/\n",
      "Jane Austen is tagged as: -1\n",
      "17092\n",
      "http://www.viaf.org/viaf/17092/\n",
      "Male\n",
      "J.D. Salinger is tagged as: Male\n",
      "87194517\n",
      "http://www.viaf.org/viaf/87194517/\n",
      "Female\n",
      "Chimamanda is tagged as: Female\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for v in VIAF:\n",
    "    print VIAF[v]\n",
    "    print v+\" is tagged as: \"+str(get_gender(VIAF[v]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
